{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 4 types of model to predict if the person will have prediabetes/diabetes or not, with the 4 models being Random Forest, Decision Tree, K Nearest Neighbors and Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  BMI  Smoker  Stroke  \\\n",
       "0                1       1         1   30       1       0   \n",
       "1                1       0         0   25       1       0   \n",
       "2                1       1         1   28       0       0   \n",
       "3                1       0         0   23       1       0   \n",
       "4                1       1         0   27       0       0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  AnyHealthcare  \\\n",
       "0                     1             0       1        1  ...              1   \n",
       "1                     0             1       1        1  ...              1   \n",
       "2                     0             0       0        1  ...              1   \n",
       "3                     0             1       0        0  ...              1   \n",
       "4                     0             1       1        1  ...              1   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  \\\n",
       "0            0        5        30        30         1    0    9          5   \n",
       "1            0        3         0         0         0    1   13          6   \n",
       "2            0        4         0         0         1    0   11          4   \n",
       "3            0        2         0         0         0    1    7          5   \n",
       "4            0        1         0         0         0    0   13          5   \n",
       "\n",
       "   Income  \n",
       "0       1  \n",
       "1       8  \n",
       "2       6  \n",
       "3       6  \n",
       "4       4  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the balanced data\n",
    "df = pd.read_csv('balanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test data for modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop(\"Diabetes_binary\",axis=1)\n",
    "response = df[\"Diabetes_binary\"]\n",
    "pred_train, pred_test, res_train, res_test = train_test_split(predictors, response, test_size = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a machine learning algorithm that creates multiple decision trees to make predictions on a dataset.\n",
    "It combines the results from several decision trees to improve accuracy and reduce overfitting.\n",
    "Each decision tree is created with a random sample with replacement from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Random Forest is: 71.41 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "max_accuracy = 0\n",
    "\n",
    "# Loop the Classifier in order to find the state with the highest accuracy\n",
    "for x in range(200):\n",
    "    rf = RandomForestClassifier(random_state=x)\n",
    "    rf.fit(pred_train,res_train)\n",
    "    res_pred_rf = rf.predict(pred_test)\n",
    "    current_accuracy = round(accuracy_score(res_pred_rf,res_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "rf = RandomForestClassifier(random_state=best_x)\n",
    "rf.fit(pred_train,res_train)\n",
    "res_pred_rf = rf.predict(pred_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "score_rf = round(accuracy_score(res_pred_rf,res_test)*100,2)\n",
    "print(\"The accuracy score achieved using Random Forest is: \"+str(score_rf)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is a binary classification method used to classify an output based on its input through the use of nodes and branches. The nodes contains information of the input and the paths represent the possible outcome to the input, depending on its classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 62.95 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "max_accuracy = 0\n",
    "\n",
    "# As with the Random Forest model, loop the Classifier function to get the state with the best accuracy\n",
    "for x in range(20):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(pred_train,res_train)\n",
    "    res_pred_dt = dt.predict(pred_test)\n",
    "    current_accuracy = round(accuracy_score(res_pred_dt,res_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(pred_train,res_train)\n",
    "res_pred_dt = dt.predict(pred_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "score_dt = round(accuracy_score(res_pred_dt,res_test)*100,2)\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors is a classification method that classifies data to the nearest neighbour in proximity to the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 69.24 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(pred_train,res_train)\n",
    "res_pred_knn=knn.predict(pred_test)\n",
    "score_knn = round(accuracy_score(res_pred_knn,res_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network is a machine learning model based on biological neural network. It takes inputs, runs it through several hidden layers in order to create the desired outcome.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary modules if they are not in your libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1972/1972 [==============================] - 2s 616us/step - loss: 0.6088 - accuracy: 0.6804\n",
      "Epoch 2/300\n",
      "1972/1972 [==============================] - 1s 596us/step - loss: 0.5632 - accuracy: 0.7124\n",
      "Epoch 3/300\n",
      "1972/1972 [==============================] - 1s 585us/step - loss: 0.5579 - accuracy: 0.7156\n",
      "Epoch 4/300\n",
      "1972/1972 [==============================] - 1s 582us/step - loss: 0.5546 - accuracy: 0.7171\n",
      "Epoch 5/300\n",
      "1972/1972 [==============================] - 1s 613us/step - loss: 0.5520 - accuracy: 0.7184\n",
      "Epoch 6/300\n",
      "1972/1972 [==============================] - 1s 571us/step - loss: 0.5500 - accuracy: 0.7206\n",
      "Epoch 7/300\n",
      "1972/1972 [==============================] - 1s 564us/step - loss: 0.5483 - accuracy: 0.7225\n",
      "Epoch 8/300\n",
      "1972/1972 [==============================] - 1s 578us/step - loss: 0.5468 - accuracy: 0.7224\n",
      "Epoch 9/300\n",
      "1972/1972 [==============================] - 1s 576us/step - loss: 0.5465 - accuracy: 0.7239\n",
      "Epoch 10/300\n",
      "1972/1972 [==============================] - 1s 612us/step - loss: 0.5451 - accuracy: 0.7240\n",
      "Epoch 11/300\n",
      "1972/1972 [==============================] - 1s 577us/step - loss: 0.5443 - accuracy: 0.7247\n",
      "Epoch 12/300\n",
      "1972/1972 [==============================] - 1s 591us/step - loss: 0.5437 - accuracy: 0.7246\n",
      "Epoch 13/300\n",
      "1972/1972 [==============================] - 1s 572us/step - loss: 0.5434 - accuracy: 0.7246\n",
      "Epoch 14/300\n",
      "1972/1972 [==============================] - 1s 567us/step - loss: 0.5422 - accuracy: 0.7266\n",
      "Epoch 15/300\n",
      "1972/1972 [==============================] - 1s 584us/step - loss: 0.5414 - accuracy: 0.7262\n",
      "Epoch 16/300\n",
      "1972/1972 [==============================] - 1s 576us/step - loss: 0.5414 - accuracy: 0.7271\n",
      "Epoch 17/300\n",
      "1972/1972 [==============================] - 1s 580us/step - loss: 0.5416 - accuracy: 0.7271\n",
      "Epoch 18/300\n",
      "1972/1972 [==============================] - 1s 574us/step - loss: 0.5408 - accuracy: 0.7274\n",
      "Epoch 19/300\n",
      "1972/1972 [==============================] - 1s 590us/step - loss: 0.5404 - accuracy: 0.7272\n",
      "Epoch 20/300\n",
      "1972/1972 [==============================] - 1s 587us/step - loss: 0.5405 - accuracy: 0.7266\n",
      "Epoch 21/300\n",
      "1972/1972 [==============================] - 1s 592us/step - loss: 0.5404 - accuracy: 0.7269\n",
      "Epoch 22/300\n",
      "1972/1972 [==============================] - 1s 577us/step - loss: 0.5396 - accuracy: 0.7287\n",
      "Epoch 23/300\n",
      "1972/1972 [==============================] - 1s 572us/step - loss: 0.5393 - accuracy: 0.7272\n",
      "Epoch 24/300\n",
      "1972/1972 [==============================] - 1s 584us/step - loss: 0.5394 - accuracy: 0.7279\n",
      "Epoch 25/300\n",
      "1972/1972 [==============================] - 1s 579us/step - loss: 0.5391 - accuracy: 0.7276\n",
      "Epoch 26/300\n",
      "1972/1972 [==============================] - 1s 593us/step - loss: 0.5390 - accuracy: 0.7289\n",
      "Epoch 27/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5390 - accuracy: 0.7288\n",
      "Epoch 28/300\n",
      "1972/1972 [==============================] - 1s 586us/step - loss: 0.5391 - accuracy: 0.7278\n",
      "Epoch 29/300\n",
      "1972/1972 [==============================] - 1s 586us/step - loss: 0.5387 - accuracy: 0.7294\n",
      "Epoch 30/300\n",
      "1972/1972 [==============================] - 1s 579us/step - loss: 0.5387 - accuracy: 0.7270\n",
      "Epoch 31/300\n",
      "1972/1972 [==============================] - 1s 587us/step - loss: 0.5390 - accuracy: 0.7273\n",
      "Epoch 32/300\n",
      "1972/1972 [==============================] - 1s 584us/step - loss: 0.5388 - accuracy: 0.7287\n",
      "Epoch 33/300\n",
      "1972/1972 [==============================] - 1s 580us/step - loss: 0.5387 - accuracy: 0.7281\n",
      "Epoch 34/300\n",
      "1972/1972 [==============================] - 1s 580us/step - loss: 0.5383 - accuracy: 0.7288\n",
      "Epoch 35/300\n",
      "1972/1972 [==============================] - 1s 575us/step - loss: 0.5385 - accuracy: 0.7286\n",
      "Epoch 36/300\n",
      "1972/1972 [==============================] - 1s 577us/step - loss: 0.5382 - accuracy: 0.7287\n",
      "Epoch 37/300\n",
      "1972/1972 [==============================] - 1s 596us/step - loss: 0.5383 - accuracy: 0.7287\n",
      "Epoch 38/300\n",
      "1972/1972 [==============================] - 1s 590us/step - loss: 0.5384 - accuracy: 0.7282\n",
      "Epoch 39/300\n",
      "1972/1972 [==============================] - 1s 601us/step - loss: 0.5384 - accuracy: 0.7294\n",
      "Epoch 40/300\n",
      "1972/1972 [==============================] - 1s 560us/step - loss: 0.5385 - accuracy: 0.7287\n",
      "Epoch 41/300\n",
      "1972/1972 [==============================] - 1s 557us/step - loss: 0.5381 - accuracy: 0.7281\n",
      "Epoch 42/300\n",
      "1972/1972 [==============================] - 1s 622us/step - loss: 0.5386 - accuracy: 0.7283\n",
      "Epoch 43/300\n",
      "1972/1972 [==============================] - 1s 592us/step - loss: 0.5380 - accuracy: 0.7280\n",
      "Epoch 44/300\n",
      "1972/1972 [==============================] - 1s 607us/step - loss: 0.5376 - accuracy: 0.7299\n",
      "Epoch 45/300\n",
      "1972/1972 [==============================] - 1s 586us/step - loss: 0.5382 - accuracy: 0.7284\n",
      "Epoch 46/300\n",
      "1972/1972 [==============================] - 1s 578us/step - loss: 0.5379 - accuracy: 0.7281\n",
      "Epoch 47/300\n",
      "1972/1972 [==============================] - 1s 597us/step - loss: 0.5380 - accuracy: 0.7295\n",
      "Epoch 48/300\n",
      "1972/1972 [==============================] - 1s 585us/step - loss: 0.5382 - accuracy: 0.7281\n",
      "Epoch 49/300\n",
      "1972/1972 [==============================] - 1s 566us/step - loss: 0.5379 - accuracy: 0.7298\n",
      "Epoch 50/300\n",
      "1972/1972 [==============================] - 1s 618us/step - loss: 0.5377 - accuracy: 0.7293\n",
      "Epoch 51/300\n",
      "1972/1972 [==============================] - 1s 602us/step - loss: 0.5373 - accuracy: 0.7288\n",
      "Epoch 52/300\n",
      "1972/1972 [==============================] - 1s 596us/step - loss: 0.5377 - accuracy: 0.7289\n",
      "Epoch 53/300\n",
      "1972/1972 [==============================] - 1s 594us/step - loss: 0.5379 - accuracy: 0.7279\n",
      "Epoch 54/300\n",
      "1972/1972 [==============================] - 1s 595us/step - loss: 0.5377 - accuracy: 0.7295\n",
      "Epoch 55/300\n",
      "1972/1972 [==============================] - 1s 598us/step - loss: 0.5379 - accuracy: 0.7290\n",
      "Epoch 56/300\n",
      "1972/1972 [==============================] - 1s 594us/step - loss: 0.5377 - accuracy: 0.7274\n",
      "Epoch 57/300\n",
      "1972/1972 [==============================] - 1s 609us/step - loss: 0.5379 - accuracy: 0.7295\n",
      "Epoch 58/300\n",
      "1972/1972 [==============================] - 1s 587us/step - loss: 0.5380 - accuracy: 0.7276\n",
      "Epoch 59/300\n",
      "1972/1972 [==============================] - 1s 582us/step - loss: 0.5377 - accuracy: 0.7288\n",
      "Epoch 60/300\n",
      "1972/1972 [==============================] - 1s 613us/step - loss: 0.5381 - accuracy: 0.7278\n",
      "Epoch 61/300\n",
      "1972/1972 [==============================] - 1s 579us/step - loss: 0.5379 - accuracy: 0.7284\n",
      "Epoch 62/300\n",
      "1972/1972 [==============================] - 1s 614us/step - loss: 0.5378 - accuracy: 0.7284\n",
      "Epoch 63/300\n",
      "1972/1972 [==============================] - 1s 609us/step - loss: 0.5379 - accuracy: 0.7286\n",
      "Epoch 64/300\n",
      "1972/1972 [==============================] - 1s 598us/step - loss: 0.5375 - accuracy: 0.7293\n",
      "Epoch 65/300\n",
      "1972/1972 [==============================] - 1s 598us/step - loss: 0.5378 - accuracy: 0.7287\n",
      "Epoch 66/300\n",
      "1972/1972 [==============================] - 1s 589us/step - loss: 0.5375 - accuracy: 0.7286\n",
      "Epoch 67/300\n",
      "1972/1972 [==============================] - 1s 616us/step - loss: 0.5374 - accuracy: 0.7294\n",
      "Epoch 68/300\n",
      "1972/1972 [==============================] - 1s 578us/step - loss: 0.5376 - accuracy: 0.7295\n",
      "Epoch 69/300\n",
      "1972/1972 [==============================] - 1s 600us/step - loss: 0.5375 - accuracy: 0.7291\n",
      "Epoch 70/300\n",
      "1972/1972 [==============================] - 1s 604us/step - loss: 0.5372 - accuracy: 0.7297\n",
      "Epoch 71/300\n",
      "1972/1972 [==============================] - 1s 585us/step - loss: 0.5379 - accuracy: 0.7288\n",
      "Epoch 72/300\n",
      "1972/1972 [==============================] - 1s 607us/step - loss: 0.5375 - accuracy: 0.7298\n",
      "Epoch 73/300\n",
      "1972/1972 [==============================] - 1s 584us/step - loss: 0.5377 - accuracy: 0.7280\n",
      "Epoch 74/300\n",
      "1972/1972 [==============================] - 1s 585us/step - loss: 0.5375 - accuracy: 0.7289\n",
      "Epoch 75/300\n",
      "1972/1972 [==============================] - 1s 592us/step - loss: 0.5375 - accuracy: 0.7294\n",
      "Epoch 76/300\n",
      "1972/1972 [==============================] - 1s 638us/step - loss: 0.5372 - accuracy: 0.7296\n",
      "Epoch 77/300\n",
      "1972/1972 [==============================] - 1s 621us/step - loss: 0.5374 - accuracy: 0.7301\n",
      "Epoch 78/300\n",
      "1972/1972 [==============================] - 1s 742us/step - loss: 0.5374 - accuracy: 0.7296\n",
      "Epoch 79/300\n",
      "1972/1972 [==============================] - 1s 685us/step - loss: 0.5374 - accuracy: 0.7294\n",
      "Epoch 80/300\n",
      "1972/1972 [==============================] - 1s 665us/step - loss: 0.5374 - accuracy: 0.7291\n",
      "Epoch 81/300\n",
      "1972/1972 [==============================] - 1s 590us/step - loss: 0.5373 - accuracy: 0.7291\n",
      "Epoch 82/300\n",
      "1972/1972 [==============================] - 1s 610us/step - loss: 0.5376 - accuracy: 0.7296\n",
      "Epoch 83/300\n",
      "1972/1972 [==============================] - 1s 603us/step - loss: 0.5374 - accuracy: 0.7297\n",
      "Epoch 84/300\n",
      "1972/1972 [==============================] - 1s 662us/step - loss: 0.5370 - accuracy: 0.7291\n",
      "Epoch 85/300\n",
      "1972/1972 [==============================] - 1s 604us/step - loss: 0.5376 - accuracy: 0.7295\n",
      "Epoch 86/300\n",
      "1972/1972 [==============================] - 1s 619us/step - loss: 0.5369 - accuracy: 0.7283\n",
      "Epoch 87/300\n",
      "1972/1972 [==============================] - 1s 604us/step - loss: 0.5373 - accuracy: 0.7291\n",
      "Epoch 88/300\n",
      "1972/1972 [==============================] - 1s 617us/step - loss: 0.5373 - accuracy: 0.7294\n",
      "Epoch 89/300\n",
      "1972/1972 [==============================] - 1s 596us/step - loss: 0.5372 - accuracy: 0.7292\n",
      "Epoch 90/300\n",
      "1972/1972 [==============================] - 1s 621us/step - loss: 0.5374 - accuracy: 0.7298\n",
      "Epoch 91/300\n",
      "1972/1972 [==============================] - 1s 675us/step - loss: 0.5372 - accuracy: 0.7292\n",
      "Epoch 92/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5370 - accuracy: 0.7288\n",
      "Epoch 93/300\n",
      "1972/1972 [==============================] - 1s 674us/step - loss: 0.5373 - accuracy: 0.7290\n",
      "Epoch 94/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5372 - accuracy: 0.7288\n",
      "Epoch 95/300\n",
      "1972/1972 [==============================] - 1s 612us/step - loss: 0.5372 - accuracy: 0.7289\n",
      "Epoch 96/300\n",
      "1972/1972 [==============================] - 1s 602us/step - loss: 0.5370 - accuracy: 0.7291\n",
      "Epoch 97/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5371 - accuracy: 0.7290\n",
      "Epoch 98/300\n",
      "1972/1972 [==============================] - 1s 646us/step - loss: 0.5371 - accuracy: 0.7280\n",
      "Epoch 99/300\n",
      "1972/1972 [==============================] - 1s 628us/step - loss: 0.5372 - accuracy: 0.7295\n",
      "Epoch 100/300\n",
      "1972/1972 [==============================] - 1s 645us/step - loss: 0.5371 - accuracy: 0.7302\n",
      "Epoch 101/300\n",
      "1972/1972 [==============================] - 1s 648us/step - loss: 0.5372 - accuracy: 0.7299\n",
      "Epoch 102/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5370 - accuracy: 0.7306\n",
      "Epoch 103/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5369 - accuracy: 0.7286\n",
      "Epoch 104/300\n",
      "1972/1972 [==============================] - 1s 654us/step - loss: 0.5373 - accuracy: 0.7293\n",
      "Epoch 105/300\n",
      "1972/1972 [==============================] - 1s 642us/step - loss: 0.5372 - accuracy: 0.7279\n",
      "Epoch 106/300\n",
      "1972/1972 [==============================] - 1s 648us/step - loss: 0.5369 - accuracy: 0.7302\n",
      "Epoch 107/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5367 - accuracy: 0.7297\n",
      "Epoch 108/300\n",
      "1972/1972 [==============================] - 1s 646us/step - loss: 0.5367 - accuracy: 0.7295\n",
      "Epoch 109/300\n",
      "1972/1972 [==============================] - 1s 678us/step - loss: 0.5362 - accuracy: 0.7298\n",
      "Epoch 110/300\n",
      "1972/1972 [==============================] - 1s 620us/step - loss: 0.5366 - accuracy: 0.7297\n",
      "Epoch 111/300\n",
      "1972/1972 [==============================] - 1s 709us/step - loss: 0.5368 - accuracy: 0.7290\n",
      "Epoch 112/300\n",
      "1972/1972 [==============================] - 1s 623us/step - loss: 0.5367 - accuracy: 0.7301\n",
      "Epoch 113/300\n",
      "1972/1972 [==============================] - 1s 672us/step - loss: 0.5361 - accuracy: 0.7294\n",
      "Epoch 114/300\n",
      "1972/1972 [==============================] - 1s 677us/step - loss: 0.5365 - accuracy: 0.7293\n",
      "Epoch 115/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5364 - accuracy: 0.7297\n",
      "Epoch 116/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5366 - accuracy: 0.7290\n",
      "Epoch 117/300\n",
      "1972/1972 [==============================] - 1s 641us/step - loss: 0.5365 - accuracy: 0.7298\n",
      "Epoch 118/300\n",
      "1972/1972 [==============================] - 1s 658us/step - loss: 0.5363 - accuracy: 0.7301\n",
      "Epoch 119/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5362 - accuracy: 0.7305\n",
      "Epoch 120/300\n",
      "1972/1972 [==============================] - 1s 625us/step - loss: 0.5362 - accuracy: 0.7303\n",
      "Epoch 121/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5364 - accuracy: 0.7301\n",
      "Epoch 122/300\n",
      "1972/1972 [==============================] - 1s 635us/step - loss: 0.5365 - accuracy: 0.7297\n",
      "Epoch 123/300\n",
      "1972/1972 [==============================] - 1s 640us/step - loss: 0.5363 - accuracy: 0.7293\n",
      "Epoch 124/300\n",
      "1972/1972 [==============================] - 1s 662us/step - loss: 0.5364 - accuracy: 0.7295\n",
      "Epoch 125/300\n",
      "1972/1972 [==============================] - 1s 700us/step - loss: 0.5362 - accuracy: 0.7296\n",
      "Epoch 126/300\n",
      "1972/1972 [==============================] - 1s 625us/step - loss: 0.5365 - accuracy: 0.7286\n",
      "Epoch 127/300\n",
      "1972/1972 [==============================] - 1s 659us/step - loss: 0.5362 - accuracy: 0.7302\n",
      "Epoch 128/300\n",
      "1972/1972 [==============================] - 1s 633us/step - loss: 0.5361 - accuracy: 0.7306\n",
      "Epoch 129/300\n",
      "1972/1972 [==============================] - 1s 617us/step - loss: 0.5366 - accuracy: 0.7288\n",
      "Epoch 130/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5363 - accuracy: 0.7300\n",
      "Epoch 131/300\n",
      "1972/1972 [==============================] - 1s 613us/step - loss: 0.5364 - accuracy: 0.7297\n",
      "Epoch 132/300\n",
      "1972/1972 [==============================] - 1s 621us/step - loss: 0.5362 - accuracy: 0.7298\n",
      "Epoch 133/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5364 - accuracy: 0.7291\n",
      "Epoch 134/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5360 - accuracy: 0.7299\n",
      "Epoch 135/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5362 - accuracy: 0.7300\n",
      "Epoch 136/300\n",
      "1972/1972 [==============================] - 1s 589us/step - loss: 0.5365 - accuracy: 0.7296\n",
      "Epoch 137/300\n",
      "1972/1972 [==============================] - 1s 594us/step - loss: 0.5358 - accuracy: 0.7293\n",
      "Epoch 138/300\n",
      "1972/1972 [==============================] - 1s 607us/step - loss: 0.5362 - accuracy: 0.7296\n",
      "Epoch 139/300\n",
      "1972/1972 [==============================] - 1s 592us/step - loss: 0.5362 - accuracy: 0.7306\n",
      "Epoch 140/300\n",
      "1972/1972 [==============================] - 1s 606us/step - loss: 0.5362 - accuracy: 0.7295\n",
      "Epoch 141/300\n",
      "1972/1972 [==============================] - 1s 595us/step - loss: 0.5360 - accuracy: 0.7297\n",
      "Epoch 142/300\n",
      "1972/1972 [==============================] - 1s 564us/step - loss: 0.5360 - accuracy: 0.7304\n",
      "Epoch 143/300\n",
      "1972/1972 [==============================] - 1s 554us/step - loss: 0.5364 - accuracy: 0.7297\n",
      "Epoch 144/300\n",
      "1972/1972 [==============================] - 1s 581us/step - loss: 0.5363 - accuracy: 0.7299\n",
      "Epoch 145/300\n",
      "1972/1972 [==============================] - 1s 574us/step - loss: 0.5359 - accuracy: 0.7308\n",
      "Epoch 146/300\n",
      "1972/1972 [==============================] - 1s 578us/step - loss: 0.5362 - accuracy: 0.7297\n",
      "Epoch 147/300\n",
      "1972/1972 [==============================] - 1s 606us/step - loss: 0.5360 - accuracy: 0.7298\n",
      "Epoch 148/300\n",
      "1972/1972 [==============================] - 1s 597us/step - loss: 0.5360 - accuracy: 0.7299\n",
      "Epoch 149/300\n",
      "1972/1972 [==============================] - 1s 606us/step - loss: 0.5364 - accuracy: 0.7287\n",
      "Epoch 150/300\n",
      "1972/1972 [==============================] - 1s 635us/step - loss: 0.5362 - accuracy: 0.7292\n",
      "Epoch 151/300\n",
      "1972/1972 [==============================] - 1s 646us/step - loss: 0.5362 - accuracy: 0.7302\n",
      "Epoch 152/300\n",
      "1972/1972 [==============================] - 1s 629us/step - loss: 0.5361 - accuracy: 0.7293\n",
      "Epoch 153/300\n",
      "1972/1972 [==============================] - 1s 683us/step - loss: 0.5360 - accuracy: 0.7295\n",
      "Epoch 154/300\n",
      "1972/1972 [==============================] - 1s 648us/step - loss: 0.5361 - accuracy: 0.7306\n",
      "Epoch 155/300\n",
      "1972/1972 [==============================] - 1s 645us/step - loss: 0.5361 - accuracy: 0.7301\n",
      "Epoch 156/300\n",
      "1972/1972 [==============================] - 1s 644us/step - loss: 0.5360 - accuracy: 0.7299\n",
      "Epoch 157/300\n",
      "1972/1972 [==============================] - 1s 625us/step - loss: 0.5360 - accuracy: 0.7297\n",
      "Epoch 158/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5357 - accuracy: 0.7302\n",
      "Epoch 159/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5362 - accuracy: 0.7291\n",
      "Epoch 160/300\n",
      "1972/1972 [==============================] - 1s 612us/step - loss: 0.5359 - accuracy: 0.7301\n",
      "Epoch 161/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5364 - accuracy: 0.7293\n",
      "Epoch 162/300\n",
      "1972/1972 [==============================] - 1s 606us/step - loss: 0.5360 - accuracy: 0.7296\n",
      "Epoch 163/300\n",
      "1972/1972 [==============================] - 1s 608us/step - loss: 0.5359 - accuracy: 0.7297\n",
      "Epoch 164/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5358 - accuracy: 0.7298\n",
      "Epoch 165/300\n",
      "1972/1972 [==============================] - 1s 602us/step - loss: 0.5359 - accuracy: 0.7307\n",
      "Epoch 166/300\n",
      "1972/1972 [==============================] - 1s 586us/step - loss: 0.5360 - accuracy: 0.7301\n",
      "Epoch 167/300\n",
      "1972/1972 [==============================] - 1s 605us/step - loss: 0.5361 - accuracy: 0.7288\n",
      "Epoch 168/300\n",
      "1972/1972 [==============================] - 1s 621us/step - loss: 0.5361 - accuracy: 0.7299\n",
      "Epoch 169/300\n",
      "1972/1972 [==============================] - 1s 616us/step - loss: 0.5362 - accuracy: 0.7295\n",
      "Epoch 170/300\n",
      "1972/1972 [==============================] - 1s 626us/step - loss: 0.5356 - accuracy: 0.7307\n",
      "Epoch 171/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5359 - accuracy: 0.7288\n",
      "Epoch 172/300\n",
      "1972/1972 [==============================] - 1s 630us/step - loss: 0.5358 - accuracy: 0.7299\n",
      "Epoch 173/300\n",
      "1972/1972 [==============================] - 1s 645us/step - loss: 0.5360 - accuracy: 0.7288\n",
      "Epoch 174/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5360 - accuracy: 0.7286\n",
      "Epoch 175/300\n",
      "1972/1972 [==============================] - 1s 666us/step - loss: 0.5360 - accuracy: 0.7295\n",
      "Epoch 176/300\n",
      "1972/1972 [==============================] - 1s 659us/step - loss: 0.5360 - accuracy: 0.7292\n",
      "Epoch 177/300\n",
      "1972/1972 [==============================] - 1s 625us/step - loss: 0.5358 - accuracy: 0.7297\n",
      "Epoch 178/300\n",
      "1972/1972 [==============================] - 1s 592us/step - loss: 0.5360 - accuracy: 0.7299\n",
      "Epoch 179/300\n",
      "1972/1972 [==============================] - 1s 630us/step - loss: 0.5358 - accuracy: 0.7289\n",
      "Epoch 180/300\n",
      "1972/1972 [==============================] - 1s 622us/step - loss: 0.5361 - accuracy: 0.7289\n",
      "Epoch 181/300\n",
      "1972/1972 [==============================] - 1s 632us/step - loss: 0.5359 - accuracy: 0.7299\n",
      "Epoch 182/300\n",
      "1972/1972 [==============================] - 1s 597us/step - loss: 0.5357 - accuracy: 0.7302\n",
      "Epoch 183/300\n",
      "1972/1972 [==============================] - 1s 673us/step - loss: 0.5357 - accuracy: 0.7284\n",
      "Epoch 184/300\n",
      "1972/1972 [==============================] - 1s 640us/step - loss: 0.5359 - accuracy: 0.7304\n",
      "Epoch 185/300\n",
      "1972/1972 [==============================] - 1s 696us/step - loss: 0.5359 - accuracy: 0.7292\n",
      "Epoch 186/300\n",
      "1972/1972 [==============================] - 1s 714us/step - loss: 0.5361 - accuracy: 0.7295\n",
      "Epoch 187/300\n",
      "1972/1972 [==============================] - 1s 727us/step - loss: 0.5360 - accuracy: 0.7300\n",
      "Epoch 188/300\n",
      "1972/1972 [==============================] - 1s 676us/step - loss: 0.5361 - accuracy: 0.7302\n",
      "Epoch 189/300\n",
      "1972/1972 [==============================] - 1s 653us/step - loss: 0.5357 - accuracy: 0.7302\n",
      "Epoch 190/300\n",
      "1972/1972 [==============================] - 1s 703us/step - loss: 0.5361 - accuracy: 0.7287\n",
      "Epoch 191/300\n",
      "1972/1972 [==============================] - 1s 715us/step - loss: 0.5358 - accuracy: 0.7292\n",
      "Epoch 192/300\n",
      "1972/1972 [==============================] - 1s 719us/step - loss: 0.5360 - accuracy: 0.7296\n",
      "Epoch 193/300\n",
      "1972/1972 [==============================] - 2s 916us/step - loss: 0.5361 - accuracy: 0.7296\n",
      "Epoch 194/300\n",
      "1972/1972 [==============================] - 2s 792us/step - loss: 0.5359 - accuracy: 0.7292\n",
      "Epoch 195/300\n",
      "1972/1972 [==============================] - 2s 851us/step - loss: 0.5359 - accuracy: 0.7301\n",
      "Epoch 196/300\n",
      "1972/1972 [==============================] - 1s 743us/step - loss: 0.5360 - accuracy: 0.7294\n",
      "Epoch 197/300\n",
      "1972/1972 [==============================] - 2s 765us/step - loss: 0.5356 - accuracy: 0.7300\n",
      "Epoch 198/300\n",
      "1972/1972 [==============================] - 2s 804us/step - loss: 0.5359 - accuracy: 0.7296\n",
      "Epoch 199/300\n",
      "1972/1972 [==============================] - 1s 739us/step - loss: 0.5356 - accuracy: 0.7294\n",
      "Epoch 200/300\n",
      "1972/1972 [==============================] - 2s 805us/step - loss: 0.5360 - accuracy: 0.7301\n",
      "Epoch 201/300\n",
      "1972/1972 [==============================] - 1s 696us/step - loss: 0.5356 - accuracy: 0.7294\n",
      "Epoch 202/300\n",
      "1972/1972 [==============================] - 1s 686us/step - loss: 0.5356 - accuracy: 0.7288\n",
      "Epoch 203/300\n",
      "1972/1972 [==============================] - 1s 716us/step - loss: 0.5356 - accuracy: 0.7305\n",
      "Epoch 204/300\n",
      "1972/1972 [==============================] - 1s 699us/step - loss: 0.5358 - accuracy: 0.7296\n",
      "Epoch 205/300\n",
      "1972/1972 [==============================] - 1s 707us/step - loss: 0.5358 - accuracy: 0.7295\n",
      "Epoch 206/300\n",
      "1972/1972 [==============================] - 2s 808us/step - loss: 0.5360 - accuracy: 0.7298\n",
      "Epoch 207/300\n",
      "1972/1972 [==============================] - 1s 735us/step - loss: 0.5358 - accuracy: 0.7304\n",
      "Epoch 208/300\n",
      "1972/1972 [==============================] - 2s 807us/step - loss: 0.5359 - accuracy: 0.7289\n",
      "Epoch 209/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5356 - accuracy: 0.7298\n",
      "Epoch 210/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5358 - accuracy: 0.7299\n",
      "Epoch 211/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5358 - accuracy: 0.7299\n",
      "Epoch 212/300\n",
      "1972/1972 [==============================] - 1s 673us/step - loss: 0.5357 - accuracy: 0.7289\n",
      "Epoch 213/300\n",
      "1972/1972 [==============================] - 1s 676us/step - loss: 0.5357 - accuracy: 0.7292\n",
      "Epoch 214/300\n",
      "1972/1972 [==============================] - 1s 690us/step - loss: 0.5358 - accuracy: 0.7293\n",
      "Epoch 215/300\n",
      "1972/1972 [==============================] - 2s 768us/step - loss: 0.5355 - accuracy: 0.7294\n",
      "Epoch 216/300\n",
      "1972/1972 [==============================] - 1s 741us/step - loss: 0.5358 - accuracy: 0.7301\n",
      "Epoch 217/300\n",
      "1972/1972 [==============================] - 1s 708us/step - loss: 0.5359 - accuracy: 0.7299\n",
      "Epoch 218/300\n",
      "1972/1972 [==============================] - 1s 667us/step - loss: 0.5355 - accuracy: 0.7296\n",
      "Epoch 219/300\n",
      "1972/1972 [==============================] - 1s 756us/step - loss: 0.5355 - accuracy: 0.7289\n",
      "Epoch 220/300\n",
      "1972/1972 [==============================] - 1s 723us/step - loss: 0.5356 - accuracy: 0.7296\n",
      "Epoch 221/300\n",
      "1972/1972 [==============================] - 1s 718us/step - loss: 0.5358 - accuracy: 0.7298\n",
      "Epoch 222/300\n",
      "1972/1972 [==============================] - 1s 733us/step - loss: 0.5357 - accuracy: 0.7307\n",
      "Epoch 223/300\n",
      "1972/1972 [==============================] - 2s 767us/step - loss: 0.5357 - accuracy: 0.7296\n",
      "Epoch 224/300\n",
      "1972/1972 [==============================] - 1s 710us/step - loss: 0.5357 - accuracy: 0.7295\n",
      "Epoch 225/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5356 - accuracy: 0.7294\n",
      "Epoch 226/300\n",
      "1972/1972 [==============================] - 1s 685us/step - loss: 0.5356 - accuracy: 0.7298\n",
      "Epoch 227/300\n",
      "1972/1972 [==============================] - 1s 678us/step - loss: 0.5357 - accuracy: 0.7300\n",
      "Epoch 228/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5355 - accuracy: 0.7296\n",
      "Epoch 229/300\n",
      "1972/1972 [==============================] - 1s 738us/step - loss: 0.5356 - accuracy: 0.7295\n",
      "Epoch 230/300\n",
      "1972/1972 [==============================] - 1s 629us/step - loss: 0.5358 - accuracy: 0.7300\n",
      "Epoch 231/300\n",
      "1972/1972 [==============================] - 1s 680us/step - loss: 0.5354 - accuracy: 0.7299\n",
      "Epoch 232/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5357 - accuracy: 0.7295\n",
      "Epoch 233/300\n",
      "1972/1972 [==============================] - 2s 767us/step - loss: 0.5354 - accuracy: 0.7297\n",
      "Epoch 234/300\n",
      "1972/1972 [==============================] - 1s 737us/step - loss: 0.5355 - accuracy: 0.7303\n",
      "Epoch 235/300\n",
      "1972/1972 [==============================] - 1s 672us/step - loss: 0.5353 - accuracy: 0.7294\n",
      "Epoch 236/300\n",
      "1972/1972 [==============================] - 1s 707us/step - loss: 0.5356 - accuracy: 0.7288\n",
      "Epoch 237/300\n",
      "1972/1972 [==============================] - 1s 654us/step - loss: 0.5356 - accuracy: 0.7293\n",
      "Epoch 238/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5356 - accuracy: 0.7300\n",
      "Epoch 239/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5354 - accuracy: 0.7293\n",
      "Epoch 240/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5355 - accuracy: 0.7299\n",
      "Epoch 241/300\n",
      "1972/1972 [==============================] - 1s 664us/step - loss: 0.5354 - accuracy: 0.7304\n",
      "Epoch 242/300\n",
      "1972/1972 [==============================] - 1s 643us/step - loss: 0.5355 - accuracy: 0.7290\n",
      "Epoch 243/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5356 - accuracy: 0.7304\n",
      "Epoch 244/300\n",
      "1972/1972 [==============================] - 1s 657us/step - loss: 0.5357 - accuracy: 0.7299\n",
      "Epoch 245/300\n",
      "1972/1972 [==============================] - 1s 690us/step - loss: 0.5355 - accuracy: 0.7293\n",
      "Epoch 246/300\n",
      "1972/1972 [==============================] - 1s 703us/step - loss: 0.5355 - accuracy: 0.7301\n",
      "Epoch 247/300\n",
      "1972/1972 [==============================] - 1s 693us/step - loss: 0.5351 - accuracy: 0.7302\n",
      "Epoch 248/300\n",
      "1972/1972 [==============================] - 1s 673us/step - loss: 0.5354 - accuracy: 0.7291\n",
      "Epoch 249/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5354 - accuracy: 0.7302\n",
      "Epoch 250/300\n",
      "1972/1972 [==============================] - 1s 659us/step - loss: 0.5355 - accuracy: 0.7301\n",
      "Epoch 251/300\n",
      "1972/1972 [==============================] - 1s 667us/step - loss: 0.5354 - accuracy: 0.7301\n",
      "Epoch 252/300\n",
      "1972/1972 [==============================] - 1s 658us/step - loss: 0.5353 - accuracy: 0.7301\n",
      "Epoch 253/300\n",
      "1972/1972 [==============================] - 1s 644us/step - loss: 0.5354 - accuracy: 0.7300\n",
      "Epoch 254/300\n",
      "1972/1972 [==============================] - 1s 651us/step - loss: 0.5353 - accuracy: 0.7293\n",
      "Epoch 255/300\n",
      "1972/1972 [==============================] - 1s 688us/step - loss: 0.5352 - accuracy: 0.7298\n",
      "Epoch 256/300\n",
      "1972/1972 [==============================] - 1s 645us/step - loss: 0.5353 - accuracy: 0.7293\n",
      "Epoch 257/300\n",
      "1972/1972 [==============================] - 1s 710us/step - loss: 0.5355 - accuracy: 0.7308\n",
      "Epoch 258/300\n",
      "1972/1972 [==============================] - 1s 688us/step - loss: 0.5354 - accuracy: 0.7297\n",
      "Epoch 259/300\n",
      "1972/1972 [==============================] - 1s 665us/step - loss: 0.5350 - accuracy: 0.7303\n",
      "Epoch 260/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5352 - accuracy: 0.7299\n",
      "Epoch 261/300\n",
      "1972/1972 [==============================] - 1s 618us/step - loss: 0.5354 - accuracy: 0.7296\n",
      "Epoch 262/300\n",
      "1972/1972 [==============================] - 1s 609us/step - loss: 0.5350 - accuracy: 0.7302\n",
      "Epoch 263/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5352 - accuracy: 0.7298\n",
      "Epoch 264/300\n",
      "1972/1972 [==============================] - 1s 607us/step - loss: 0.5354 - accuracy: 0.7295\n",
      "Epoch 265/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5350 - accuracy: 0.7296\n",
      "Epoch 266/300\n",
      "1972/1972 [==============================] - 1s 606us/step - loss: 0.5354 - accuracy: 0.7298\n",
      "Epoch 267/300\n",
      "1972/1972 [==============================] - 1s 598us/step - loss: 0.5354 - accuracy: 0.7300\n",
      "Epoch 268/300\n",
      "1972/1972 [==============================] - 1s 604us/step - loss: 0.5353 - accuracy: 0.7292\n",
      "Epoch 269/300\n",
      "1972/1972 [==============================] - 1s 601us/step - loss: 0.5354 - accuracy: 0.7294\n",
      "Epoch 270/300\n",
      "1972/1972 [==============================] - 1s 599us/step - loss: 0.5352 - accuracy: 0.7302\n",
      "Epoch 271/300\n",
      "1972/1972 [==============================] - 1s 603us/step - loss: 0.5352 - accuracy: 0.7299\n",
      "Epoch 272/300\n",
      "1972/1972 [==============================] - 1s 628us/step - loss: 0.5352 - accuracy: 0.7303\n",
      "Epoch 273/300\n",
      "1972/1972 [==============================] - 1s 612us/step - loss: 0.5351 - accuracy: 0.7289\n",
      "Epoch 274/300\n",
      "1972/1972 [==============================] - 1s 599us/step - loss: 0.5352 - accuracy: 0.7296\n",
      "Epoch 275/300\n",
      "1972/1972 [==============================] - 1s 599us/step - loss: 0.5353 - accuracy: 0.7297\n",
      "Epoch 276/300\n",
      "1972/1972 [==============================] - 1s 601us/step - loss: 0.5351 - accuracy: 0.7295\n",
      "Epoch 277/300\n",
      "1972/1972 [==============================] - 1s 683us/step - loss: 0.5352 - accuracy: 0.7296\n",
      "Epoch 278/300\n",
      "1972/1972 [==============================] - 1s 626us/step - loss: 0.5352 - accuracy: 0.7291\n",
      "Epoch 279/300\n",
      "1972/1972 [==============================] - 1s 626us/step - loss: 0.5353 - accuracy: 0.7302\n",
      "Epoch 280/300\n",
      "1972/1972 [==============================] - 1s 665us/step - loss: 0.5353 - accuracy: 0.7293\n",
      "Epoch 281/300\n",
      "1972/1972 [==============================] - 1s 658us/step - loss: 0.5354 - accuracy: 0.7293\n",
      "Epoch 282/300\n",
      "1972/1972 [==============================] - 1s 690us/step - loss: 0.5354 - accuracy: 0.7291\n",
      "Epoch 283/300\n",
      "1972/1972 [==============================] - 1s 699us/step - loss: 0.5350 - accuracy: 0.7308\n",
      "Epoch 284/300\n",
      "1972/1972 [==============================] - 1s 642us/step - loss: 0.5354 - accuracy: 0.7296\n",
      "Epoch 285/300\n",
      "1972/1972 [==============================] - 1s 691us/step - loss: 0.5352 - accuracy: 0.7303\n",
      "Epoch 286/300\n",
      "1972/1972 [==============================] - 1s 624us/step - loss: 0.5351 - accuracy: 0.7299\n",
      "Epoch 287/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5352 - accuracy: 0.7292\n",
      "Epoch 288/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5352 - accuracy: 0.7290\n",
      "Epoch 289/300\n",
      "1972/1972 [==============================] - 1s 676us/step - loss: 0.5353 - accuracy: 0.7291\n",
      "Epoch 290/300\n",
      "1972/1972 [==============================] - 1s 713us/step - loss: 0.5350 - accuracy: 0.7294\n",
      "Epoch 291/300\n",
      "1972/1972 [==============================] - 1s 726us/step - loss: 0.5352 - accuracy: 0.7294\n",
      "Epoch 292/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5352 - accuracy: 0.7299\n",
      "Epoch 293/300\n",
      "1972/1972 [==============================] - 1s 672us/step - loss: 0.5352 - accuracy: 0.7295\n",
      "Epoch 294/300\n",
      "1972/1972 [==============================] - 1s 681us/step - loss: 0.5353 - accuracy: 0.7289\n",
      "Epoch 295/300\n",
      "1972/1972 [==============================] - 1s 741us/step - loss: 0.5352 - accuracy: 0.7299\n",
      "Epoch 296/300\n",
      "1972/1972 [==============================] - 1s 609us/step - loss: 0.5350 - accuracy: 0.7294\n",
      "Epoch 297/300\n",
      "1972/1972 [==============================] - 1s 604us/step - loss: 0.5352 - accuracy: 0.7304\n",
      "Epoch 298/300\n",
      "1972/1972 [==============================] - 1s 599us/step - loss: 0.5350 - accuracy: 0.7298\n",
      "Epoch 299/300\n",
      "1972/1972 [==============================] - 1s 610us/step - loss: 0.5349 - accuracy: 0.7304\n",
      "Epoch 300/300\n",
      "1972/1972 [==============================] - 1s 653us/step - loss: 0.5350 - accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5ae04d930>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=20))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# Train the model several times to improve accuracy\n",
    "model.fit(pred_train,res_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 0s 500us/step\n",
      "The accuracy score achieved using Neural Network is: 72.63 %\n"
     ]
    }
   ],
   "source": [
    "res_pred_nn = model.predict(pred_test)\n",
    "rounded = [round(x[0]) for x in res_pred_nn]\n",
    "\n",
    "res_pred_nn = rounded\n",
    "score_nn = round(accuracy_score(res_pred_nn,res_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Random Forest is: 71.41 %\n",
      "The accuracy score achieved using Decision Tree is: 62.95 %\n",
      "The accuracy score achieved using K-Nearest Neighbors is: 69.24 %\n",
      "The accuracy score achieved using Neural Network is: 72.63 %\n"
     ]
    }
   ],
   "source": [
    "scores = [score_rf,score_dt,score_knn,score_nn]\n",
    "models = [\"Random Forest\",\"Decision Tree\",\"K-Nearest Neighbors\",\"Neural Network\"]    \n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"The accuracy score achieved using \"+models[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "\n",
    "barPlot = sns.barplot(x=models,y=scores)\n",
    "for i in barPlot.containers:\n",
    "    barPlot.bar_label(i,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

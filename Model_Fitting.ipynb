{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 4 types of model to predict if the person will have prediabetes/diabetes or not, with the 4 models being Random Forest, Decision Tree, K Nearest Neighbors and Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  BMI  Smoker  Stroke  \\\n",
       "0                1       1         1   30       1       0   \n",
       "1                1       0         0   25       1       0   \n",
       "2                1       1         1   28       0       0   \n",
       "3                1       0         0   23       1       0   \n",
       "4                1       1         0   27       0       0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  AnyHealthcare  \\\n",
       "0                     1             0       1        1  ...              1   \n",
       "1                     0             1       1        1  ...              1   \n",
       "2                     0             0       0        1  ...              1   \n",
       "3                     0             1       0        0  ...              1   \n",
       "4                     0             1       1        1  ...              1   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  \\\n",
       "0            0        5        30        30         1    0    9          5   \n",
       "1            0        3         0         0         0    1   13          6   \n",
       "2            0        4         0         0         1    0   11          4   \n",
       "3            0        2         0         0         0    1    7          5   \n",
       "4            0        1         0         0         0    0   13          5   \n",
       "\n",
       "   Income  \n",
       "0       1  \n",
       "1       8  \n",
       "2       6  \n",
       "3       6  \n",
       "4       4  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the balanced data\n",
    "df = pd.read_csv('balanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test data for modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop(\"Diabetes_binary\",axis=1)\n",
    "response = df[\"Diabetes_binary\"]\n",
    "pred_train, pred_test, res_train, res_test = train_test_split(predictors, response, test_size = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a machine learning algorithm that creates multiple decision trees to make predictions on a dataset.\n",
    "It combines the results from several decision trees to improve accuracy and reduce overfitting.\n",
    "Each decision tree is created with a random sample with replacement from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Random Forest is: 71.45 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "max_accuracy = 0\n",
    "\n",
    "# Loop the Classifier in order to find the state with the highest accuracy\n",
    "for x in range(200):\n",
    "    rf = RandomForestClassifier(random_state=x)\n",
    "    rf.fit(pred_train,res_train)\n",
    "    res_pred_rf = rf.predict(pred_test)\n",
    "    current_accuracy = round(accuracy_score(res_pred_rf,res_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "rf = RandomForestClassifier(random_state=best_x)\n",
    "rf.fit(pred_train,res_train)\n",
    "res_pred_rf = rf.predict(pred_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "score_rf = round(accuracy_score(res_pred_rf,res_test)*100,2)\n",
    "print(\"The accuracy score achieved using Random Forest is: \"+str(score_rf)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is a binary classification method used to classify an output based on its input through the use of nodes and branches. The nodes contains information of the input and the paths represent the possible outcome to the input, depending on its classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 62.93 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "max_accuracy = 0\n",
    "\n",
    "# As with the Random Forest model, loop the Classifier function to get the state with the best accuracy\n",
    "for x in range(200):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(pred_train,res_train)\n",
    "    res_pred_dt = dt.predict(pred_test)\n",
    "    current_accuracy = round(accuracy_score(res_pred_dt,res_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(pred_train,res_train)\n",
    "res_pred_dt = dt.predict(pred_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "score_dt = round(accuracy_score(res_pred_dt,res_test)*100,2)\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sk37c\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 68.87 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(pred_train,res_train)\n",
    "res_pred_knn=knn.predict(pred_test)\n",
    "score_knn = round(accuracy_score(res_pred_knn,res_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary modules if they are not in your libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1972/1972 [==============================] - 4s 1ms/step - loss: 0.7037 - accuracy: 0.6273\n",
      "Epoch 2/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5606 - accuracy: 0.7112\n",
      "Epoch 3/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5545 - accuracy: 0.7160\n",
      "Epoch 4/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5513 - accuracy: 0.7187\n",
      "Epoch 5/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5492 - accuracy: 0.7203\n",
      "Epoch 6/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5473 - accuracy: 0.7207\n",
      "Epoch 7/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5456 - accuracy: 0.7226\n",
      "Epoch 8/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5441 - accuracy: 0.7231\n",
      "Epoch 9/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5433 - accuracy: 0.7242\n",
      "Epoch 10/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5422 - accuracy: 0.7254\n",
      "Epoch 11/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5414 - accuracy: 0.7260\n",
      "Epoch 12/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5404 - accuracy: 0.7260\n",
      "Epoch 13/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5404 - accuracy: 0.7253\n",
      "Epoch 14/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5394 - accuracy: 0.7263\n",
      "Epoch 15/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5395 - accuracy: 0.7266\n",
      "Epoch 16/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5387 - accuracy: 0.7267\n",
      "Epoch 17/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5382 - accuracy: 0.7271\n",
      "Epoch 18/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5382 - accuracy: 0.7277\n",
      "Epoch 19/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5381 - accuracy: 0.7271\n",
      "Epoch 20/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5376 - accuracy: 0.7279\n",
      "Epoch 21/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5372 - accuracy: 0.7289\n",
      "Epoch 22/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5373 - accuracy: 0.7291\n",
      "Epoch 23/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5369 - accuracy: 0.7289\n",
      "Epoch 24/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5368 - accuracy: 0.7281\n",
      "Epoch 25/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5366 - accuracy: 0.7290\n",
      "Epoch 26/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5365 - accuracy: 0.7299\n",
      "Epoch 27/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5364 - accuracy: 0.7296\n",
      "Epoch 28/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5365 - accuracy: 0.7292\n",
      "Epoch 29/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5366 - accuracy: 0.7285\n",
      "Epoch 30/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5362 - accuracy: 0.7298\n",
      "Epoch 31/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5362 - accuracy: 0.7296\n",
      "Epoch 32/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5361 - accuracy: 0.7294\n",
      "Epoch 33/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5357 - accuracy: 0.7300\n",
      "Epoch 34/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5358 - accuracy: 0.7307\n",
      "Epoch 35/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5364 - accuracy: 0.7299\n",
      "Epoch 36/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5358 - accuracy: 0.7306\n",
      "Epoch 37/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5357 - accuracy: 0.7306\n",
      "Epoch 38/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5357 - accuracy: 0.7307\n",
      "Epoch 39/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5357 - accuracy: 0.7307\n",
      "Epoch 40/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5357 - accuracy: 0.7299\n",
      "Epoch 41/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5358 - accuracy: 0.7303\n",
      "Epoch 42/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5354 - accuracy: 0.7302\n",
      "Epoch 43/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5352 - accuracy: 0.7301\n",
      "Epoch 44/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5355 - accuracy: 0.7304\n",
      "Epoch 45/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5353 - accuracy: 0.7296\n",
      "Epoch 46/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5353 - accuracy: 0.7301\n",
      "Epoch 47/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7306\n",
      "Epoch 48/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5355 - accuracy: 0.7310\n",
      "Epoch 49/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5352 - accuracy: 0.7309\n",
      "Epoch 50/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5352 - accuracy: 0.7309\n",
      "Epoch 51/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5353 - accuracy: 0.7307\n",
      "Epoch 52/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5353 - accuracy: 0.7307\n",
      "Epoch 53/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5353 - accuracy: 0.7300\n",
      "Epoch 54/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5355 - accuracy: 0.7318\n",
      "Epoch 55/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5353 - accuracy: 0.7302\n",
      "Epoch 56/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5352 - accuracy: 0.7304\n",
      "Epoch 57/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5353 - accuracy: 0.7311\n",
      "Epoch 58/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5353 - accuracy: 0.7306\n",
      "Epoch 59/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5351 - accuracy: 0.7309\n",
      "Epoch 60/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7303\n",
      "Epoch 61/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7306\n",
      "Epoch 62/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5355 - accuracy: 0.7308\n",
      "Epoch 63/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5350 - accuracy: 0.7301\n",
      "Epoch 64/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7301\n",
      "Epoch 65/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7302\n",
      "Epoch 66/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7305\n",
      "Epoch 67/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5351 - accuracy: 0.7309\n",
      "Epoch 68/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5351 - accuracy: 0.7308\n",
      "Epoch 69/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7309\n",
      "Epoch 70/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7310\n",
      "Epoch 71/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5351 - accuracy: 0.7308\n",
      "Epoch 72/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5351 - accuracy: 0.7305\n",
      "Epoch 73/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7306\n",
      "Epoch 74/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5346 - accuracy: 0.7320\n",
      "Epoch 75/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7318\n",
      "Epoch 76/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7303\n",
      "Epoch 77/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5353 - accuracy: 0.7306\n",
      "Epoch 78/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7301\n",
      "Epoch 79/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7301\n",
      "Epoch 80/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7307\n",
      "Epoch 81/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7306\n",
      "Epoch 82/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7314\n",
      "Epoch 83/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7318\n",
      "Epoch 84/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7304\n",
      "Epoch 85/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5348 - accuracy: 0.7306\n",
      "Epoch 86/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5349 - accuracy: 0.7313\n",
      "Epoch 87/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5347 - accuracy: 0.7312\n",
      "Epoch 88/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7315\n",
      "Epoch 89/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5348 - accuracy: 0.7300\n",
      "Epoch 90/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5349 - accuracy: 0.7313\n",
      "Epoch 91/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7311\n",
      "Epoch 92/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5348 - accuracy: 0.7303\n",
      "Epoch 93/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7315\n",
      "Epoch 94/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5350 - accuracy: 0.7305\n",
      "Epoch 95/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7315\n",
      "Epoch 96/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7311\n",
      "Epoch 97/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7314\n",
      "Epoch 98/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7325\n",
      "Epoch 99/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7315\n",
      "Epoch 100/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7308\n",
      "Epoch 101/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7309\n",
      "Epoch 102/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5344 - accuracy: 0.7326\n",
      "Epoch 103/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5348 - accuracy: 0.7304\n",
      "Epoch 104/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7314\n",
      "Epoch 105/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7306\n",
      "Epoch 106/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7313\n",
      "Epoch 107/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5342 - accuracy: 0.7315\n",
      "Epoch 108/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7310\n",
      "Epoch 109/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7303\n",
      "Epoch 110/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5346 - accuracy: 0.7325\n",
      "Epoch 111/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7315\n",
      "Epoch 112/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7308\n",
      "Epoch 113/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7310\n",
      "Epoch 114/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7314\n",
      "Epoch 115/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7321\n",
      "Epoch 116/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7306\n",
      "Epoch 117/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5347 - accuracy: 0.7310\n",
      "Epoch 118/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7305\n",
      "Epoch 119/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5343 - accuracy: 0.7304\n",
      "Epoch 120/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5343 - accuracy: 0.7313\n",
      "Epoch 121/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7320\n",
      "Epoch 122/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7310\n",
      "Epoch 123/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7324\n",
      "Epoch 124/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7304\n",
      "Epoch 125/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7313\n",
      "Epoch 126/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7315\n",
      "Epoch 127/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7335\n",
      "Epoch 128/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7312\n",
      "Epoch 129/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7318\n",
      "Epoch 130/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5345 - accuracy: 0.7316\n",
      "Epoch 131/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7311\n",
      "Epoch 132/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7313\n",
      "Epoch 133/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7324\n",
      "Epoch 134/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5343 - accuracy: 0.7309\n",
      "Epoch 135/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7303\n",
      "Epoch 136/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7320\n",
      "Epoch 137/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7314\n",
      "Epoch 138/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7317\n",
      "Epoch 139/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7313\n",
      "Epoch 140/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5343 - accuracy: 0.7311\n",
      "Epoch 141/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5343 - accuracy: 0.7313\n",
      "Epoch 142/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7314\n",
      "Epoch 143/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7316\n",
      "Epoch 144/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7315\n",
      "Epoch 145/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7320\n",
      "Epoch 146/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7308\n",
      "Epoch 147/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7316\n",
      "Epoch 148/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7316\n",
      "Epoch 149/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7331\n",
      "Epoch 150/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7324\n",
      "Epoch 151/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7319\n",
      "Epoch 152/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7313\n",
      "Epoch 153/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7324\n",
      "Epoch 154/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7321\n",
      "Epoch 155/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7306\n",
      "Epoch 156/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7311\n",
      "Epoch 157/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7312\n",
      "Epoch 158/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7306\n",
      "Epoch 159/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7316\n",
      "Epoch 160/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5342 - accuracy: 0.7316\n",
      "Epoch 161/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7309\n",
      "Epoch 162/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7310\n",
      "Epoch 163/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7314\n",
      "Epoch 164/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7316\n",
      "Epoch 165/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7325\n",
      "Epoch 166/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7322\n",
      "Epoch 167/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7323\n",
      "Epoch 168/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7317\n",
      "Epoch 169/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7317\n",
      "Epoch 170/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7314\n",
      "Epoch 171/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7316\n",
      "Epoch 172/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7309\n",
      "Epoch 173/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5338 - accuracy: 0.7315\n",
      "Epoch 174/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7323\n",
      "Epoch 175/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7323\n",
      "Epoch 176/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7320\n",
      "Epoch 177/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5338 - accuracy: 0.7324\n",
      "Epoch 178/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7312\n",
      "Epoch 179/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7318\n",
      "Epoch 180/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7314\n",
      "Epoch 181/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7320\n",
      "Epoch 182/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7316\n",
      "Epoch 183/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7318\n",
      "Epoch 184/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7317\n",
      "Epoch 185/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7317\n",
      "Epoch 186/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7320\n",
      "Epoch 187/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7314\n",
      "Epoch 188/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7320\n",
      "Epoch 189/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5336 - accuracy: 0.7319\n",
      "Epoch 190/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5340 - accuracy: 0.7313\n",
      "Epoch 191/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5339 - accuracy: 0.7324\n",
      "Epoch 192/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7321\n",
      "Epoch 193/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7317\n",
      "Epoch 194/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7320\n",
      "Epoch 195/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7315\n",
      "Epoch 196/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7323\n",
      "Epoch 197/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7323\n",
      "Epoch 198/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7324\n",
      "Epoch 199/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7321\n",
      "Epoch 200/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7318\n",
      "Epoch 201/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7325\n",
      "Epoch 202/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7327\n",
      "Epoch 203/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7327\n",
      "Epoch 204/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7321\n",
      "Epoch 205/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7321\n",
      "Epoch 206/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7309\n",
      "Epoch 207/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7331\n",
      "Epoch 208/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7321\n",
      "Epoch 209/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7323\n",
      "Epoch 210/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7327\n",
      "Epoch 211/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7314\n",
      "Epoch 212/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7321\n",
      "Epoch 213/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7319\n",
      "Epoch 214/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7327\n",
      "Epoch 215/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7315\n",
      "Epoch 216/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7325\n",
      "Epoch 217/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7325\n",
      "Epoch 218/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7322\n",
      "Epoch 219/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7320\n",
      "Epoch 220/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7317\n",
      "Epoch 221/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7316\n",
      "Epoch 222/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7326\n",
      "Epoch 223/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7323\n",
      "Epoch 224/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7320\n",
      "Epoch 225/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7330\n",
      "Epoch 226/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7327\n",
      "Epoch 227/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7328\n",
      "Epoch 228/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7325\n",
      "Epoch 229/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7330\n",
      "Epoch 230/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7323\n",
      "Epoch 231/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7319\n",
      "Epoch 232/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7316\n",
      "Epoch 233/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7323\n",
      "Epoch 234/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7314\n",
      "Epoch 235/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7318\n",
      "Epoch 236/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7321\n",
      "Epoch 237/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7331\n",
      "Epoch 238/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7328\n",
      "Epoch 239/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5336 - accuracy: 0.7327\n",
      "Epoch 240/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5332 - accuracy: 0.7327\n",
      "Epoch 241/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7322\n",
      "Epoch 242/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7329\n",
      "Epoch 243/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7320\n",
      "Epoch 244/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7313\n",
      "Epoch 245/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7313\n",
      "Epoch 246/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7322\n",
      "Epoch 247/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7324\n",
      "Epoch 248/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5335 - accuracy: 0.7333\n",
      "Epoch 249/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7329\n",
      "Epoch 250/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5336 - accuracy: 0.7335\n",
      "Epoch 251/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7327\n",
      "Epoch 252/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5337 - accuracy: 0.7324\n",
      "Epoch 253/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7330\n",
      "Epoch 254/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5335 - accuracy: 0.7319\n",
      "Epoch 255/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7318\n",
      "Epoch 256/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.7325\n",
      "Epoch 257/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.7317\n",
      "Epoch 258/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7320\n",
      "Epoch 259/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.7334\n",
      "Epoch 260/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7326\n",
      "Epoch 261/300\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 0.5334 - accuracy: 0.7322\n",
      "Epoch 262/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7321\n",
      "Epoch 263/300\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 0.5334 - accuracy: 0.7321\n",
      "Epoch 264/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5331 - accuracy: 0.7321\n",
      "Epoch 265/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5335 - accuracy: 0.7321\n",
      "Epoch 266/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5335 - accuracy: 0.7321\n",
      "Epoch 267/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7321\n",
      "Epoch 268/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5330 - accuracy: 0.7317\n",
      "Epoch 269/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.7336\n",
      "Epoch 270/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7322\n",
      "Epoch 271/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5335 - accuracy: 0.7323\n",
      "Epoch 272/300\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 0.5334 - accuracy: 0.7348\n",
      "Epoch 273/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5330 - accuracy: 0.7332\n",
      "Epoch 274/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7324\n",
      "Epoch 275/300\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 0.5333 - accuracy: 0.7329\n",
      "Epoch 276/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7331\n",
      "Epoch 277/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7331\n",
      "Epoch 278/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7321\n",
      "Epoch 279/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.7325\n",
      "Epoch 280/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7325\n",
      "Epoch 281/300\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 0.5334 - accuracy: 0.7329\n",
      "Epoch 282/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7323\n",
      "Epoch 283/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7322\n",
      "Epoch 284/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7320\n",
      "Epoch 285/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5332 - accuracy: 0.7328\n",
      "Epoch 286/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5331 - accuracy: 0.7329\n",
      "Epoch 287/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7323\n",
      "Epoch 288/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5329 - accuracy: 0.7336\n",
      "Epoch 289/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5335 - accuracy: 0.7320\n",
      "Epoch 290/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7322\n",
      "Epoch 291/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7331\n",
      "Epoch 292/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7320\n",
      "Epoch 293/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7338\n",
      "Epoch 294/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5333 - accuracy: 0.7327\n",
      "Epoch 295/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5334 - accuracy: 0.7319\n",
      "Epoch 296/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5332 - accuracy: 0.7322\n",
      "Epoch 297/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7327\n",
      "Epoch 298/300\n",
      "1972/1972 [==============================] - 3s 1ms/step - loss: 0.5332 - accuracy: 0.7331\n",
      "Epoch 299/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.7320\n",
      "Epoch 300/300\n",
      "1972/1972 [==============================] - 3s 2ms/step - loss: 0.5332 - accuracy: 0.7330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b1a0aff4c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(pred_train,res_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 1s 1ms/step\n",
      "The accuracy score achieved using Neural Network is: 72.89 %\n"
     ]
    }
   ],
   "source": [
    "res_pred_nn = model.predict(pred_test)\n",
    "rounded = [round(x[0]) for x in res_pred_nn]\n",
    "\n",
    "res_pred_nn = rounded\n",
    "score_nn = round(accuracy_score(res_pred_nn,res_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Random Forest is: 71.45 %\n",
      "The accuracy score achieved using Decision Tree is: 62.93 %\n",
      "The accuracy score achieved using K-Nearest Neighbors is: 68.87 %\n",
      "The accuracy score achieved using Neural Network is: 72.89 %\n"
     ]
    }
   ],
   "source": [
    "scores = [score_rf,score_dt,score_knn,score_nn]\n",
    "models = [\"Random Forest\",\"Decision Tree\",\"K-Nearest Neighbors\",\"Neural Network\"]    \n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"The accuracy score achieved using \"+models[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sk37c\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Models', ylabel='Accuracy score'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNEAAAKrCAYAAADfxRvjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYOUlEQVR4nO3deZhWZf0/8PcME6AIiqRiWkEo4IaQ4p4imrnkglSaioqp4JoLiqYmVu4LLmgqoOKSK7jkrmWaSiommuHy1RAXRBRRRFlnnt8f/picwA7D9kzwel3XXBdz3+c853Oei/ueZ95zn3MqSqVSKQAAAADA16osdwEAAAAA0NAJ0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACgQFW5CyiHUqmUmppSucsAAAAAoIwqKytSUVExX9sukyFaTU0pH3/8ebnLAAAAAKCMVl65WRo1mr8QzeWcAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFCgqtwFAAAAwJJUWVmRysqKcpcBzENNTSk1NaVylzFPQjQAAACWGZWVFWm50nKpbNSo3KUA81BTXZ3Jn0xrkEGaEA0AAIBlRmVlRSobNcro31+VqePfL3c5wFes8K3V0/mwPqmsrBCiAQAAQEMwdfz7mTJuXLnLAP6HeLAAAAAAABQQogEAAABAASEaAAAAABQQogEAAABAASEaAAAAABQQogEAAABAASEaAAAAABSoKncBy4rKyopUVlaUuwxgHmpqSqmpKZW7DAAAABowIdoSUFlZkZVWWj6NGln4Bw1RdXVNPvnkC0EaAAAAX0uItgRUVlakUaPKXH7zU3lv4qflLgf4ijVWXTFH/HzLVFZWCNEAAAD4WkK0Jei9iZ/mrfcml7sMAAAAAOrJ9YUAAAAAUECIBgAAAAAFhGgAAAAAUECIBgAAAAAFyvpggWeeeSb777//PPvWXHPN/OlPf8orr7ySM888My+//HJWWmml9OrVK7/4xS+WcKUAAAAALMvKGqJ16dIlTz75ZJ22119/PYceemj69u2byZMnp3fv3tl+++1zxhlnZPTo0TnjjDOy0korpWfPnmWqGgAAAIBlTVlDtMaNG2eVVVap/X7WrFk5++yzs8MOO+SnP/1prrrqqjRu3DgDBgxIVVVV2rVrl3HjxmXw4MFCNAAAAACWmAZ1T7Sbbrop77//fk4++eQkyahRo9K1a9dUVf0769tss80yduzYTJo0qVxlAgAAALCMKetKtK+aMWNGrrzyyhxwwAFZddVVkyQTJkxI+/bt62w3p2/8+PFp1arVAh+vqmrJ5YeNGjWorBKYB+MUAGDZ4HMfNHwNdZw2mBDt7rvvzowZM9KrV6/atunTp6dx48Z1tmvSpEmSL0O3BVVZWZGWLZst8P7A0qdFi+XKXQIAAABpuL+fNZgQ7a677soOO+yQli1b1rY1bdo0M2fOrLPdnPBs+eWXX+Bj1dSUMmXKFwu8f301alTZYP8DAF+aMmVaqqtryl0GAACLmd/PoOFbkr+ftWix3HyvfGsQIdrHH3+cF154IX369KnT3rp160ycOLFO25zvV1tttYU65uzZflkG/q26usa8AAAA0AA01N/PGsRFpn//+99TUVGRTTbZpE57165d8/zzz6e6urq2beTIkWnbtu1C3Q8NAAAAAOqjQYRor776ar797W9nueXqLqnt2bNnpk6dmlNOOSVvvPFGRowYkWHDhs21Yg0AAAAAFqcGEaJ99NFHWWmlleZqb9WqVYYMGZKxY8emR48eGTRoUE488cT06NFjyRcJAAAAwDKrQdwTbcCAAV/b16lTp9x6661LrhgAAAAA+A8NYiUaAAAAADRkDWIlGgAAy4bKyopUVlaUuwzga9TUlFJTUyp3GQANkhANAIAlorKyIiu1XC6NKhuVuxTga1TXVOeTydMEaQDzIEQDAGCJqKysSKPKRrnq8esz/tMPyl0O8B++teJq6bPN/qmsrBCiAcyDEA0AgCVq/KcfZNykd8tdBgBAvXiwAAAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQAEhGgAAAAAUEKIBAAAAQIGqchcAwJJRWVmRysqKcpcBfI2amlJqakrlLgMAgK8hRANYBlRWVqRly+VSWdmo3KUAX6OmpjqTJ08TpAEANFBCNIBlwJer0Bpl7L2DM23S++UuB/gPy7VaPW1/fEgqKyuEaAAADZQQDWAZMm3S+5n2wdvlLgMAAOB/jgcLAAAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFGgQIdpdd92VnXfeORtssEF22WWXPPDAA7V9r7zySvbbb7907tw53bp1y9ChQ8tYKQAAAADLorKHaHfffXd+9atfZa+99sq9996bnXfeOccdd1xeeOGFTJ48Ob17906bNm0yfPjwHHXUUbnkkksyfPjwcpcNAAAAwDKkqpwHL5VKueSSS3LAAQfkgAMOSJIcccQR+fvf/55nn302zz77bBo3bpwBAwakqqoq7dq1y7hx4zJ48OD07NmznKUDAAAAsAwpa4j2r3/9K++991523XXXOu1zLtk85JBD0rVr11RV/bvMzTbbLFdddVUmTZqUVq1aLfCxq6qW3CK8Ro3KvuAPKLC0j9Ol/fxgabG0j9Wl/fxgabG0j9Wl/fxgadBQx2lZQ7S33norSfLFF1/kF7/4RcaMGZM111wzhx12WLp3754JEyakffv2dfZZddVVkyTjx49f4BCtsrIiLVs2W6jagaVLixbLlbsEAHMR0CCYi4Bya6jzUFlDtKlTpyZJ+vfvnyOPPDL9+vXLQw89lMMPPzzXXnttpk+fnsaNG9fZp0mTJkmSGTNmLPBxa2pKmTLliwUvvJ4aNapssP8BgC9NmTIt1dU15S5jsTEPwf8GcxHQEJiLgHJbkvNQixbLzffKt7KGaN/4xjeSJL/4xS/So0ePJMk666yTMWPG5Nprr03Tpk0zc+bMOvvMCc+WX375hTr27NlL7w8FoP6qq2vMC0DZmYuAhsBcBJRbQ52HynqRaevWrZNkrks211prrbz77rtp3bp1Jk6cWKdvzverrbbakikSAAAAgGVeWUO0ddddN82aNcuLL75Yp/3111/Pd77znXTt2jXPP/98qqura/tGjhyZtm3bLtRDBQAAAACgPsoaojVt2jQHH3xwLr/88tx77715++238/vf/z5PPfVUevfunZ49e2bq1Kk55ZRT8sYbb2TEiBEZNmxY+vTpU86yAQAAAFjGlPWeaEly+OGHZ7nllsvAgQPzwQcfpF27drnsssuy6aabJkmGDBmSM888Mz169Mgqq6ySE088sfb+aQAAAACwJJQ9REuS3r17p3fv3vPs69SpU2699dYlXBEAAAAA/FtZL+cEAAAAgP8FQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKFD2EO29995Lhw4d5vq6/fbbkySvvPJK9ttvv3Tu3DndunXL0KFDy1wxAAAAAMuaqnIX8Nprr6VJkyZ59NFHU1FRUdvevHnzTJ48Ob17987222+fM844I6NHj84ZZ5yRlVZaKT179ixj1QAAAAAsS8oeor3++utp27ZtVl111bn6hg0blsaNG2fAgAGpqqpKu3btMm7cuAwePFiIBgAAAMASU/bLOV977bWstdZa8+wbNWpUunbtmqqqf2d9m222WcaOHZtJkyYtqRIBAAAAWMY1iJVoq6yySvbZZ5+89dZb+e53v5vDDz88P/jBDzJhwoS0b9++zvZzVqyNHz8+rVq1WuDjVlUtufywUaOyZ5VAgaV9nC7t5wdLi6V9rC7t5wdLi6V9rC7t5wdLg4Y6Tssaos2cOTNvvfVWlltuuZx44olZfvnlc8899+SQQw7Jtddem+nTp6dx48Z19mnSpEmSZMaMGQt83MrKirRs2WyhageWLi1aLFfuEgDMRUCDYC4Cyq2hzkNlDdEaN26c5557LlVVVbVh2frrr58333wzQ4cOTdOmTTNz5sw6+8wJz5ZffvkFPm5NTSlTpnyx4IXXU6NGlQ32PwDwpSlTpqW6uqbcZSw25iH432AuAhoCcxFQbktyHmrRYrn5XvlW9ss55xWGtW/fPk8++WRat26diRMn1umb8/1qq622UMedPXvp/aEA1F91dY15ASg7cxHQEJiLgHJrqPNQWS8yffXVV9OlS5eMGjWqTvvLL7+ctdZaK127ds3zzz+f6urq2r6RI0embdu2C3U/NAAAAACoj7KGaO3bt8/aa6+dM844I6NGjcqbb76Zs88+O6NHj07fvn3Ts2fPTJ06NaecckreeOONjBgxIsOGDUufPn3KWTYAAAAAy5iyXs5ZWVmZK6+8MhdccEGOOeaYTJkyJeuuu26uvfbadOjQIUkyZMiQnHnmmenRo0dWWWWVnHjiienRo0c5ywYAAABgGVP2e6KtvPLKOeuss762v1OnTrn11luXYEUAAAAAUFdZL+cEAAAAgP8FQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKLDQIdqMGTNSKpUWRS0AAAAA0CAtUIj2r3/9K8ccc0w22WSTdOnSJWPGjMmAAQNyww03LOr6AAAAAKDs6h2ivfLKK/nJT36Sf/7zn9l1111rV6F94xvfyFlnnZU777xzkRcJAAAAAOVUVd8dzj333Ky//vq55pprkiQ33XRTkuSUU07J9OnTc/3116dHjx6LtkoAAAAAKKN6r0QbPXp0DjzwwFRVVaWioqJO384775y33nprUdUGAAAAAA1CvUO0Jk2aZPr06fPs++STT9K4ceOFLgoAAAAAGpJ6h2hbbrllLr300kyYMKG2raKiIp9//nmuueaabLHFFou0QAAAAAAot3rfE+2EE07IXnvtlR133DEdO3ZMRUVFzjnnnIwdOzalUikXXXTR4qgTAAAAAMqm3ivRVl999dx999054IADUiqV8p3vfCdffPFFfvzjH2fEiBH59re/vTjqBAAAAICyqfdKtCuvvDLbbbddjj322MVRDwAAAAA0OPVeiTZkyJC8//77i6MWAAAAAGiQ6h2itWnTJv/3f/+3OGoBAAAAgAap3pdzduvWLQMHDsxjjz2WtddeO61atarTX1FRkSOOOGKRFQgAAAAA5VbvEG3QoEFJklGjRmXUqFFz9QvRAAAAAFja1DtEe/XVVxdHHQAAAADQYNU7RPuqN998M5999llWXnnlfOc731lUNQEAAABAg7JAIdq9996bc889Nx999FFt2ze/+c0cf/zx2WOPPRZVbQAAAADQINQ7RPvzn/+cE044IZtttlmOO+64fPOb38zEiRNzzz335OSTT85KK62Ubt26LYZSAQAAAKA86h2i/f73v8+OO+6YgQMH1mnv2bNnjj322Fx11VVCNAAAAACWKpX13eH1119Pjx495tnXo0cPDx4AAAAAYKlT7xCtZcuW+eSTT+bZN3ny5DRu3HhhawIAAACABqXeIdrmm2+eyy67LOPHj6/T/t577+Xyyy/PlltuuciKAwAAAICGoN73RDvuuOPSs2fP7LjjjuncuXNWWWWVfPjhhxk9enRWXHHFHH/88YujTgAAAAAom3qvRFtllVVy5513plevXpk+fXpefvnlTJ8+Pb169cqdd96ZNdZYY3HUCQAAAABlU++VaEmy0korZZdddskJJ5yQJJk4cWL+8Y9/ZMUVV1ykxQEAAABAQ1DvlWgTJkzIrrvumqOPPrq27dVXX80RRxyRffbZJx9//PEiLRAAAAAAyq3eIdp5552XmpqaDBw4sLZt6623zt13353PP/88F1544SItEAAAAADKrd4h2siRI9OvX79ssMEGddo7dOiQo48+Oo8//vgiKw4AAAAAGoJ6h2izZs1KRUXFPPuaNGmSzz//fKGLAgAAAICGpN4hWufOnXPddddl1qxZddpnzZqVYcOGpVOnTousOAAAAABoCOr9dM5jjjkm++yzT7bbbrtsvfXWadWqVT7++OP89a9/zeTJk3PDDTcsjjoBAAAAoGzqHaKtv/76ue2223LFFVfkL3/5Sz755JM0b948G2+8cQ4//PCss846i6NOAAAAACibeodoSdKxY8dceumli7oWAAAAAGiQFihEe+eddzJjxoystdZamTJlSgYOHJj3338/O+64Y/bYY49FXCIAAAAAlFe9HyzwxBNPZKeddsrw4cOTJKeffnpuu+22fPDBBzn55JNz++23L/IiAQAAAKCc6h2iXXHFFdlqq61yxBFH5LPPPssjjzySQw89NHfeeWcOPfTQXH/99YujTgAAAAAom3qHaK+++moOOOCArLDCCvnrX/+a6urq/OhHP0qSbLnllhk3btwiLxIAAAAAyqneIVqTJk0ye/bsJMlf//rXtGrVKh07dkySfPTRR2nRosUCFzN27Nh06dIlI0aMqG175ZVXst9++6Vz587p1q1bhg4dusCvDwAAAAALot4h2kYbbZRrrrkm9957bx544IHssMMOSZKXX345gwYNyve///0FKmTWrFnp169fvvjii9q2yZMnp3fv3mnTpk2GDx+eo446Kpdccknt/dgAAAAAYEmod4h28skn54MPPki/fv2y5ppr5rDDDkuS9OnTJzNnzky/fv0WqJDLLrsszZo1q9N22223pXHjxhkwYEDatWuXnj175sADD8zgwYMX6BgAAAAAsCCq6rvDt7/97dx3332ZNGlSvvnNb9a2X3755Vl33XXTuHHjehfx3HPP5dZbb81dd92Vbt261baPGjUqXbt2TVXVv8vcbLPNctVVV2XSpElp1apVvY81R1VVvfPDBdao0ZI7FrBglvZxurSfHywtlvaxurSfHywtlvaxurSfHywNGuo4rXeIliQVFRV1ArQk6dy58wIVMGXKlJx44ok59dRTs/rqq9fpmzBhQtq3b1+nbdVVV02SjB8/foFDtMrKirRs2ax4Q2CZ0aLFcuUuAcBcBDQI5iKg3BrqPLRAIdqiNGDAgHTu3Dm77rrrXH3Tp0+fa2VbkyZNkiQzZsxY4GPW1JQyZcoXxRsuIo0aVTbY/wDAl6ZMmZbq6ppyl7HYmIfgf4O5CGgIzEVAuS3JeahFi+Xme+VbWUO0u+66K6NGjcof//jHefY3bdo0M2fOrNM2JzxbfvnlF+rYs2cvvT8UgPqrrq4xLwBlZy4CGgJzEVBuDXUeKmuINnz48EyaNKnOfdCS5PTTT8/QoUPzrW99KxMnTqzTN+f71VZbbUmVCQAAAMAyrt4h2vjx4/Otb31rkRz8ggsuyPTp0+u07bDDDjn66KOz884757777sstt9yS6urqNGrUKEkycuTItG3bdqEeKgAAAAAA9VHvxx1st9126d27d/74xz8u1H3Jki9Xk333u9+t85UkrVq1yhprrJGePXtm6tSpOeWUU/LGG29kxIgRGTZsWPr06bNQxwUAAACA+qh3iHbBBRekqqoqJ510Urbccsv8+te/zujRoxdDaV+GaUOGDMnYsWPTo0ePDBo0KCeeeGJ69OixWI4HAAAAAPNS78s5d9lll+yyyy758MMPc9ddd+Xuu+/ObbfdljZt2mTPPffM7rvvvlD3K3vttdfqfN+pU6fceuutC/x6AAAAALCw6r0SbY5VVlklhxxySO69997ceeedWXXVVTNw4MB07949hx12WJ5//vlFWScAAAAAlM0Ch2hJMmrUqJx22mk58MADM2rUqGy55Zb51a9+ldmzZ2e//fbLtddeu6jqBAAAAICyqfflnOPGjcvdd9+de+65J++9917WWGON7L///unZs2dat26dJNl3333Tr1+//P73v0/v3r0XedEAAAAAsCTVO0T70Y9+lCZNmmT77bfPb3/722y++ebz3O573/te3nrrrYWtDwAAAADKrt4h2mmnnZbddtstzZs3/6/bHX744Tn88MMXuDAAAAAAaCjqfU+0fffdN4899lhOOeWU2rZRo0alR48eeeSRRxZpcQAAAADQENQ7RBsxYkROPPHETJs2rbatVatWWXPNNfPLX/5SkAYAAADAUqfeIdo111yTgw8+OBdddFFtW9u2bXPZZZeld+/eueKKKxZpgQAAAABQbvUO0d55551stdVW8+zbaqutMnbs2IUuCgAAAAAaknqHaKuuumpeeumlefaNGTMmLVu2XOiiAAAAAKAhqffTOffYY4/8/ve/T7NmzbL99ttn5ZVXzscff5xHH300gwYNyv7777846gQAAACAsql3iNanT5+8+eab+e1vf5vf/e53te2lUik77rhjjjrqqEVaIAAAAACUW71DtKqqqlx00UU57LDDMmrUqHz66adp3rx5Ntpoo3Ts2HFx1AgAAAAAZVXvEG2OtddeO2uvvfZc7Z999lmaN2++UEUBAAAAQENS7xBt5syZue666/Lss89m1qxZKZVKSb68nPOLL77IG2+8kRdffHGRFwoAAAAA5VLvEO28887LjTfemPbt2+fjjz9OkyZNsvLKK+f111/PrFmzcuSRRy6OOgEAAACgbCrru8PDDz+cAw88MPfcc0969eqV9ddfP7fffnsefvjhrLHGGqmpqVkcdQIAAABA2dQ7RPv444+zzTbbJEk6dOiQf/zjH0mS1VZbLYceemjuv//+RVshAAAAAJRZvUO05s2bZ+bMmUmSNm3a5P3338/UqVPrfA8AAAAAS5N6h2gbb7xxbrjhhnzxxRdZc801s9xyy+WRRx5JkrzwwgtZYYUVFnmRAAAAAFBO9Q7RjjjiiIwePTp9+vRJVVVV9tlnn/z617/OnnvumUsuuSQ/+tGPFkedAAAAAFA29X46Z8eOHfPAAw/k9ddfT5Icf/zxWWGFFfL3v/893bt3z6GHHrrIiwQAAACAcqp3iDZgwIDsvvvu2XLLLZMkFRUV6du37yIvDAAAAAAainpfzvnHP/4x06dPXxy1AAAAAECDVO8QbYMNNsgTTzyxOGoBAAAAgAap3pdzdujQITfccEMeeuihrLXWWmnVqlWd/oqKipx11lmLrEAAAAAAKLd6h2iPPPJIVl111STJG2+8kTfeeKNOf0VFxaKpDAAAAAAaiHqHaH/+858XRx0AAAAA0GDV+55oAAAAALCsqfdKtP33379wm+uvv36BigEAAACAhqjeIVqpVJqr7Ysvvsibb76Z5ZdfPjvssMMiKQwAAAAAGop6h2g33HDDPNs//fTT9OnTJ9/73vcWuigAAAAAaEgW2T3RVlxxxRxyyCG57rrrFtVLAgAAAECDsEgfLFAqlTJp0qRF+ZIAAAAAUHb1vpzzueeem6uturo6EyZMyKBBg7LeeustksIAAAAAoKGod4jWq1evVFRUpFQqpaKiIsm/Hzaw+uqr51e/+tWirRAAAAAAyqzeIdr1118/V1tFRUVWWGGFdOjQIZWVi/QKUQAAAAAou3qHaJtsskmqq6vz2muvZd11102STJw4Mf/4xz+y1lprCdEAAAAAWOrUO/GaMGFCdttttxx99NG1ba+++mqOOOKI7LPPPvn4448XaYEAAAAAUG71DtHOO++8VFdXZ+DAgbVtW2+9de6+++58/vnnufDCCxdpgQAAAABQbvUO0UaOHJl+/fplgw02qNPeoUOHHH300Xn88ccXWXEAAAAA0BDUO0SbNWtW7VM5/1OTJk3y+eefL3RRAAAAANCQ1DtE69y5c6677rrMmjWrTvusWbMybNiwdOrUaZEVBwAAAAANQb2fznnMMcdkn332yXbbbZett946rVq1yscff5y//vWvmTx5cm644YbFUScAAAAAlE29Q7T1118/t912W6644or85S9/ySeffJLmzZtn4403zuGHH5511llncdQJAAAAAGVT7xAtSTp27JgLL7ww3/jGN5IkX3zxRWbOnJmVVlppUdYGAAAAAA1Cve+JNnPmzJx66qn52c9+Vts2evTobLXVVjnzzDNTXV29SAsEAAAAgHKrd4h26aWX5v77788ee+xR27beeuulf//+ufPOOzN48OBFWR8AAAAAlF29L+e877770r9//+y11161bSuuuGJ69eqVysrKXHfddenbt+8iLRIAAAAAyqneK9EmT56cNddcc559bdu2zQcffLDQRQEAAABAQ1LvEK1du3Z56KGH5tn3yCOP5Lvf/e5CFwUAAAAADUm9L+c86KCDcvzxx+eTTz7J9ttvn1atWuXjjz/Oo48+mocffjhnn3324qgTAAAAAMqm3iHaLrvsks8++yyDBg3Kww8/XNvesmXL/PrXv86Pf/zjRVogAAAAAJRbvUO0JNl7772z1157ZezYsfnkk0/SokWLNGnSJLfffnu6deuWJ598clHXCQAAAABls0AhWpJUVFSkbdu2eeyxx3LllVfmqaeeSnV1db73ve8tyvoAAAAAoOwWKESbOHFibr/99txxxx2ZMGFCWrRokb322it77LFHOnXqtKhrBAAAAICyqleI9tRTT+WWW27JY489llKplE033TQTJkzIoEGD0rVr18VVIwAAAACU1XyFaEOGDMltt92Wt99+O23bts3RRx+dHj16pEmTJtlkk00Wd40AAAAAUFbzFaJdcMEF6dChQ2644YY6K84+++yzxVYYAAAAADQUlfOz0W677Za33347Bx98cPr06ZMHHnggM2fOXNy1AQAAAECDMF8r0c4777x8/vnnuffeezNixIgce+yxWXHFFbPddtuloqIiFRUVi7tOAAAAACib+VqJliTNmjXLXnvtlVtvvTX33Xdf9txzzzzxxBMplUrp379/Bg4cmNdff31x1goAAAAAZTHfIdpXtWvXLv3798/jjz+eQYMGZe21187QoUOz++67Z7fddlvUNQIAAABAWc3X5Zxfp1GjRtl+++2z/fbbZ9KkSRkxYkTuuuuuRVQaAAAAADQMC7QSbV5atWqVQw45JPfdd9+iekkAAAAAaBAWWYgGAAAAAEsrIRoAAAAAFBCiAQAAAECBsodokyZNygknnJDNNtssXbp0yaGHHpo33nijtv+VV17Jfvvtl86dO6dbt24ZOnRoGasFAAAAYFlU9hDtsMMOyzvvvJPBgwfnjjvuSNOmTXPggQdm2rRpmTx5cnr37p02bdpk+PDhOeqoo3LJJZdk+PDh5S4bAAAAgGVIVTkPPnny5Ky55po57LDDsvbaaydJDj/88Oy+++75v//7v4wcOTKNGzfOgAEDUlVVlXbt2mXcuHEZPHhwevbsWc7SAQAAAFiGlHUlWsuWLXPRRRfVBmgfffRRhg4dmtatW2ettdbKqFGj0rVr11RV/Tvr22yzzTJ27NhMmjSpXGUDAAAAsIwp60q0rzrttNNy2223pXHjxvn973+f5ZdfPhMmTEj79u3rbLfqqqsmScaPH59WrVot8PGqqpZcftioUdmvmgUKLO3jdGk/P1haLO1jdWk/P1haLO1jdWk/P1gaNNRx2mBCtAMOOCB77bVXbr755hxxxBH5wx/+kOnTp6dx48Z1tmvSpEmSZMaMGQt8rMrKirRs2Wyh6gWWLi1aLFfuEgDMRUCDYC4Cyq2hzkMNJkRba621kiS//e1vM3r06Nx4441p2rRpZs6cWWe7OeHZ8ssvv8DHqqkpZcqULxa82Hpq1Kiywf4HAL40Zcq0VFfXlLuMxcY8BP8bzEVAQ2AuAsptSc5DLVosN98r38oaok2aNCkjR47MTjvtlEaNGiVJKisr065du0ycODGtW7fOxIkT6+wz5/vVVlttoY49e/bS+0MBqL/q6hrzAlB25iKgITAXAeXWUOehsl5kOnHixBx//PF59tlna9tmzZqVMWPGpF27dunatWuef/75VFdX1/aPHDkybdu2Xaj7oQEAAABAfZQ1ROvYsWO22mqrnHHGGRk1alRef/319O/fP1OmTMmBBx6Ynj17ZurUqTnllFPyxhtvZMSIERk2bFj69OlTzrIBAAAAWMaUNUSrqKjIxRdfnM022yzHHHNMfvrTn+bTTz/NTTfdlG9961tp1apVhgwZkrFjx6ZHjx4ZNGhQTjzxxPTo0aOcZQMAAACwjCn7gwWaN2+eAQMGZMCAAfPs79SpU2699dYlWxQAAAAAfEVZV6IBAAAAwP8CIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAECBsodon3zySX79619n6623zve///38/Oc/z6hRo2r7X3nlley3337p3LlzunXrlqFDh5axWgAAAACWRWUP0Y477ri8+OKLueiii3LHHXdkvfXWyy9+8Yu8+eabmTx5cnr37p02bdpk+PDhOeqoo3LJJZdk+PDh5S4bAAAAgGVIVTkPPm7cuDz11FO5+eab8/3vfz9Jcsopp+SJJ57Ivffem6ZNm6Zx48YZMGBAqqqq0q5du4wbNy6DBw9Oz549y1k6AAAAAMuQsoZoLVu2zNVXX53111+/tq2ioiKlUimffvppXn755XTt2jVVVf8uc7PNNstVV12VSZMmpVWrVgt87KqqJbcIr1Gjsi/4Awos7eN0aT8/WFos7WN1aT8/WFos7WN1aT8/WBo01HFa1hCtRYsW2Wabbeq0PfDAA3n77bez1VZbZeDAgWnfvn2d/lVXXTVJMn78+AUO0SorK9KyZbMFKxpYKrVosVy5SwAwFwENgrkIKLeGOg+VNUT7T88//3x+9atfZbvttkv37t1z9tlnp3HjxnW2adKkSZJkxowZC3ycmppSpkz5YqFqrY9GjSob7H8A4EtTpkxLdXVNuctYbMxD8L/BXAQ0BOYioNyW5DzUosVy873yrcGEaI8++mj69euXDTfcMBdddFGSpGnTppk5c2ad7eaEZ8svv/xCHW/27KX3hwJQf9XVNeYFoOzMRUBDYC4Cyq2hzkMN4iLTG2+8MUcddVS23nrrDB48OE2bNk2StG7dOhMnTqyz7ZzvV1tttSVeJwAAAADLprKHaH/4wx/y29/+Nvvuu28uvvjiOpdvdu3aNc8//3yqq6tr20aOHJm2bdsu1EMFAAAAAKA+yhqijR07NmeddVZ++MMfpk+fPpk0aVI+/PDDfPjhh/nss8/Ss2fPTJ06NaecckreeOONjBgxIsOGDUufPn3KWTYAAAAAy5iy3hPtoYceyqxZs/LII4/kkUceqdPXo0ePnHPOORkyZEjOPPPM9OjRI6usskpOPPHE9OjRo0wVAwAAALAsKmuI1rdv3/Tt2/e/btOpU6fceuutS6giAAAAAJhb2e+JBgAAAAANnRANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAoI0QAAAACggBANAAAAAAo0qBDtiiuuSK9eveq0vfLKK9lvv/3SuXPndOvWLUOHDi1TdQAAAAAsqxpMiHbdddfl0ksvrdM2efLk9O7dO23atMnw4cNz1FFH5ZJLLsnw4cPLVCUAAAAAy6KqchfwwQcf5JRTTsnzzz+ftm3b1um77bbb0rhx4wwYMCBVVVVp165dxo0bl8GDB6dnz55lqhgAAACAZU3ZV6L985//zIorrph77rknG264YZ2+UaNGpWvXrqmq+nfWt9lmm2Xs2LGZNGnSki4VAAAAgGVU2Veide/ePd27d59n34QJE9K+ffs6bauuumqSZPz48WnVqtUCH7eqasnlh40alT2rBAos7eN0aT8/WFos7WN1aT8/WFos7WN1aT8/WBo01HFa9hDtv5k+fXoaN25cp61JkyZJkhkzZizw61ZWVqRly2YLVRuwdGnRYrlylwBgLgIaBHMRUG4NdR5q0CFa06ZNM3PmzDptc8Kz5ZdffoFft6amlClTvlio2uqjUaPKBvsfAPjSlCnTUl1dU+4yFhvzEPxvMBcBDYG5CCi3JTkPtWix3HyvfGvQIVrr1q0zceLEOm1zvl9ttdUW6rVnz156fygA9VddXWNeAMrOXAQ0BOYioNwa6jzUMC8y/f+6du2a559/PtXV1bVtI0eOTNu2bRfqfmgAAAAAUB8NOkTr2bNnpk6dmlNOOSVvvPFGRowYkWHDhqVPnz7lLg0AAACAZUiDDtFatWqVIUOGZOzYsenRo0cGDRqUE088MT169Ch3aQAAAAAsQxrUPdHOOeecudo6deqUW2+9tQzVAAAAAMCXGvRKNAAAAABoCIRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABYRoAAAAAFBAiAYAAAAABf4nQrSamppceuml+cEPfpANN9wwBx10UMaNG1fusgAAAABYRvxPhGhXXHFFbrnllvzud7/LrbfemoqKihxyyCGZOXNmuUsDAAAAYBnQ4EO0mTNn5pprrslRRx2VbbbZJh07dszAgQPzwQcf5JFHHil3eQAAAAAsAypKpVKp3EX8Ny+99FJ++tOf5sEHH0zbtm1r23/+85+nQ4cOGTBgQL1fs1QqpaZmyZ12RUVSWVmZT6dOT3V1zRI7LlCsUaPKrLhC09TU1KRhz4YLZ848NOvzKSnVVJe7HOA/VFQ2yjeatVhm5qIp0z7LbHMRNDhVlY3SYrnmy8xcNGPKlJRmm4ugIamoapQmLZbsZ6LKyopUVFTM17ZVi7mWhTZhwoQkyeqrr16nfdVVV83777+/QK9ZUVGRRo3m7w1alFZcoekSPyYwfyorG/zC3EXiG81alLsE4L9YVuaiFss1L3cJwH+xrMxFTVr4XAQNVUOdhxpmVV8xbdq0JEnjxo3rtDdp0iQzZswoR0kAAAAALGMafIjWtOmXq7f+8yECM2bMyHLLLVeOkgAAAABYxjT4EG3OZZwTJ06s0z5x4sS0bt26HCUBAAAAsIxp8CFax44ds8IKK+SZZ56pbZsyZUrGjBmTjTfeuIyVAQAAALCsaPAPFmjcuHH222+/XHDBBVl55ZWzxhpr5Pzzz0/r1q3zwx/+sNzlAQAAALAMaPAhWpIcffTRmT17dk499dRMnz49Xbt2zdChQ+d62AAAAAAALA4VpVKpVO4iAAAAAKAha/D3RAMAAACAchOiAQAAAEABIRoAAAAAFBCiAQAAAEABIRoAAAAAFBCiAQAAAEABIRpLRK9evdKhQ4c6X+uvv366d++eM888M9OnT1/sNXTv3j2XXXbZYj/OV5100klznfecr8MPP3yJ1vKfvvjii9x0001lrQEaiu7du881P3Xr1i2/+c1vMnny5EV+rPmdi3r16pWTTjppkR7/q75ufprztTiPDf9rvm7snnXWWenYsWNuu+22r933pJNOyrrrrpt//OMfc/WNGDEiHTp0WKS1Li6PPfZY3njjja/t7969e7p165apU6fO1XfSSSelV69e832syy67LN27d5/v7Yte/913302HDh3yzDPPzPdrwtJsUY7XxeWZZ55Jhw4d8u67786zf878ed11183VtyBjfvz48bnvvvsWtNx6Kzo/GqaqchfAsmOnnXbKKaecUvv9F198kSeffDJnn312qqur8+tf/7qM1S0+Xbp0meeH7iZNmpShmn+75pprMmLEiOy7775lrQMaioMOOigHHXRQkmT69Ol5/fXXc/755+e5557LzTffnBVWWGGRHOeOO+6Y7/F/2WWXpVGjRovkuPPy5JNP1v77/vvvz1lnnVWnrWnTpovt2LA0OPvss3PjjTfmnHPOyR577PFft62urs7JJ5+cESNGpHHjxkumwEXovffeS9++fXP99ddnrbXW+trt3n///Zxzzjn53e9+t1DHO+igg3xGgcVsUY3Xchs4cGC6deuWNm3aLNTr9O/fP2ussUZ22WWXRVMYSyUr0VhimjZtmlVWWaX267vf/W723Xff7Lrrrks08V/SvvGNb9Q57zlfLVq0KGtdpVKprMeHhmb55ZevHZ/f/va3s9122+Waa67Ju+++m6FDhy6y46y88spp1qzZfG270korpXnz5ovs2P/pq3PSnOPMqw2Y2znnnJMbb7wx559/fmGAliStW7fOW2+9lUGDBi3+4haD+f3c8O1vfzu33357/vrXvy7U8Zo1a5aVV155oV4D+O8W1Xgtt1VWWSUnn3xyampqyl0KywAhGmXXpEmTVFb++7/ihAkT0q9fv2yxxRZZb731ss0222TgwIG1k+KIESPSvXv33HnnnfnhD3+Y9ddfPz179swLL7xQ+xqfffZZ+vfvn4033jibb775PJf4vvDCC9l///2z0UYbZdNNN82vfvWrfPrpp7X93bt3zw033JCjjjoqG264YbbeeuvcfvvteeGFF7LHHntkww03zN5775233357od+Du+66K7vttls6deqU7t2758orr6w93zlLka+44opsueWW6d69e6ZMmZLPPvssp512WjbbbLNstNFG2X///etcJjJt2rSccsop2XLLLbPBBhtkjz32yMMPP5zky9UtgwYNynvvvWcJMfwX3/rWt/LDH/4w9957b21b0dhLkqeeeip777137dxx4YUXprq6OkndS8L+2zhN5r6cc37mrauvvjpHHXVUunTpkk033TRnnXVWZs+evcDvQa9evfKrX/0qP/3pT7PxxhvnrrvuSpIMHz48O+20Uzp16pSddtopw4YNq/Ph9YMPPsixxx6bjTfeOJtuumn69u2bt956a4HrgIZkToB28cUXz/eKhe985zs57LDDMmTIkLz00ktfu12pVMrgwYOz3XbbZcMNN8zuu++ee+65p842f/7zn7P33nunS5cu2WCDDfKTn/wkTz/9dG3/go7bu+66K7vssks22GCD/OAHP8iZZ56ZmTNn5t133812222XJNl///3/6yXpu+22WzbffPOcdtpp87xMbI6iufQ/L+d8++23c8ghh6RLly7Zaqutcs011+SHP/xhRowYUbvNrFmzcu6552bzzTdP586dc/jhh+ejjz6qc9zRo0dnt912ywYbbJCf/vSn+ec//1mnf0E+kz3++OPZc889s+GGG2bzzTfPSSedVGduhoZqcY3XZO5L1bt3756zzjorO++8czbddNP87W9/y5QpU3L66adnm222yXrrrZctt9wyp59+er1v9XPWWWflhRdeyPXXX/9ft3vsscey5557plOnTvnhD3+Yiy++ODNnzkzy5bz57LPP5s4770z37t1z5JFHpm/fvrX7vvrqq+nQoUOuvvrq2rabbrop22yzTZIvr2K4+OKLs91229V+pnv00UfrvB9zbmW08cYb13ntOf7+97+nS5cuueCCC+p1/ixZQjTKZvbs2fnLX/6Su+++O7vvvntte58+ffLxxx9n6NChefDBB3PwwQfnyiuvzJ///OfabSZOnJhbbrkl559/fm699dZUVlamf//+tX8lPeaYY/LSSy/lyiuvzDXXXJPHHnss7733Xu3+L730Unr16pW11lort956ay699NK89NJLOeigg+p8mLzwwgvzgx/8IPfee2+6deuWAQMG5PTTT89JJ52UG2+8MR9++OFCT3LXXXddTjvttOy111655557cuyxx2bo0KE577zz6mx3zz33ZNiwYbnkkkvSvHnzHHLIIXnrrbdy1VVX5bbbbkvnzp3z85//PGPGjEmSXHLJJXnttddy9dVX5/7778/WW2+dY489Nu+++27tZWutW7fOk08+mdVXX32hzgGWZu3bt8/bb7+dzz//PKVSqXDsvfjiizn44IPTuXPnjBgxImeddVZuv/32XHrppXO99n8bp/9pfuetyy67LF27ds2dd96Zo446Ktdff32dEHBBjBgxIvvvv39uvvnmbLPNNrn11ltz7rnn5ogjjsh9992XY445JoMHD66dD7/44ov06tUr1dXVufHGG3PDDTekZcuW+dnPfpYPPvhgoWqBcjv33HNz7bXX5qCDDsoPf/jDeu3bp0+fdOzYMSeffHLtL27/aeDAgfnDH/6QU089NX/84x+z//77Z8CAAbX3MX355ZdzxBFHZIcddsg999yT22+/Pa1atUq/fv3qvGZ9x+2rr76aU089NUcddVQeeuihnHXWWbn77rszZMiQrL766rn99tuTfDnHzLn0fV4qKipy5plnZsqUKTn77LPnuc38zKVfNW3atBx44IGpqanJzTffnIsvvjh33nln3nnnnTrbvfDCC/n0009z00035aqrrsro0aPn+jw1ZMiQ9O3bN3fddVc6dOiQffbZp3ZeWpDPZLNnz86RRx6Znj175v7778+gQYPy3HPPzbUPNESLY7z+NzfffHNOPfXUDBkyJN///vfTv3//vPTSS7n00kvz0EMP1V7yfuutt9brdTfZZJPst99+GThw4Nf+we6JJ57IL3/5y/z0pz/Nvffem9NPPz0PPPBATjjhhCRfzm1dunTJTjvtlDvuuCPdu3fPs88+W/uHyKeffjoVFRX529/+Vvuajz/+eO0fGI477rjcddddOeWUU3LPPfdk++23z5FHHpk//elPtdu/9957+eCDD3LnnXfm+OOPr1Pfiy++mEMOOSQHHHBA+vXrV6/zZwkrwRKw3377ldZdd91S586da786duxY6t69e+myyy4rzZo1q1QqlUrTpk0rDR06tPTuu+/W2X+rrbYqDRo0qFQqlUrDhw8vtW/fvjRmzJja/kceeaTUvn370gcffFB68803S+3bty89/fTTtf0ffvhhaf311y9deumlpVKpVPrlL39Z2nPPPesc49VXXy21b9++9Je//KVUKpVK2267bemoo46q7f+///u/Uvv27Uu33XZbbdv5559f+tGPfvS1592/f/9Sx44d65x3586dSzvssEOpVCqVampqSltssUXpnHPOqbPf9ddfX1pvvfVKU6ZMKb3zzjul9u3bl4YNG1bb//TTT5fat29fmjRpUp399t1331L//v1LpVKpdNhhh5UOOOCA0pQpU0qlUqk0e/bs0uOPP177/aWXXlradtttv7Z2WJZsu+22tfPDf7r11ltL7du3L02YMGG+xt5xxx1X+tnPflan/+GHHy7deOONcx2raJzut99+ta87v/PWYYcdVmeb3XffvXTaaacVvgdz5tb/tN9++5X22GOPOm1bb711aciQIXXa7rjjjtIGG2xQmj59eum2224rbbzxxqWZM2fW9ldXV//X9xkaum233ba01VZblTp16lTae++9S9///vdLb7/99nzt279//9J+++1XKpW+HLfrrbde6YILLiiVSnXH3ueff17aYIMNSg888ECd/S+55JLan9ljxoypnU/mePLJJ0vt27cvjR8/vlQqLdi4feSRR0rrr79+6R//+Edt/0svvVT617/+VSqVSrWfR/72t7/91/dozhj/wx/+UGrfvn3piSeemOs9mJ+59KufU+64447ShhtuWJo8eXLttnPmv+HDh9e+/pZbblmaPXt27Ta//e1vSzvttFOd+q+77rra/lmzZpW23Xbb0kUXXbTAn8nGjBlTat++fenPf/5zbdvrr79eeuWVV772fYKGYHGN1zn+83PFtttuWzriiCPqbHPDDTfMNVb22muv0sknn1wqlUqlv/3tb6X27duX3nnnnXmew1eP8cUXX5S222670t57712qrq6ea876+c9/XjrjjDPq7D9y5Mg6r//Vz12TJk0qdezYsfTcc8+VSqVS6Re/+EXpyCOPLG244YalGTNmlKZNm1bq1KlT6amnniq98cYbc80DpVKpdOSRR5Z+8pOf1Kn1q+c75/wefPDB0kYbbVS67LLL5nmeNCweLMAS07179/Tr1y81NTV58cUXc/bZZ2eLLbZI3759U1X15X/Fpk2bZr/99suDDz6YYcOGZdy4cXn11VczceLEua5xb9euXe2/59y3Z9asWXn99deTJBtssEFt/ze/+c18+9vfrv3+9ddfz5Zbblnn9Tp06JAWLVrktddeq12W27Zt29r+OTfYXnPNNWvbmjRp8rV/SZ5j/fXXn2u12pwbhX/88cf56KOPstFGG9Xp79q1a2bNmpV//etfadWqVZLku9/9bm3/nEsP5vzlY46ZM2dmxowZSZJDDjkkffv2zeabb54uXbpkyy23zC677OIeR1BPn332WZJkhRVWmK+x99prr2WLLbao0/91q1XqM07nd9766tyYfDk/zpo1a35Pd56+Ov98/PHHmTBhQi655JI693aqqanJjBkz8u6772bMmDGZOnVqNtlkkzqvM2PGjLz55psLVQuU09SpU3P11VenY8eO2XXXXXPcccflD3/4Q77xjW8k+XKF0umnn167/UYbbZQhQ4bUeY0OHTrksMMOy+WXXz7X3PDGG29kxowZ6d+/f04++eTa9tmzZ2fmzJmZPn161llnnay44ooZPHhwxo4dm7feeiuvvPJKktReNp7Uf9z+4Ac/SJcuXdKzZ8+0adMmW2yxRbbbbrusv/76C/Re7b333nnooYdy2mmnzbUadn7m0q8aM2ZM2rZtm5VWWqm2rUOHDnPNld/5znfqPIxlxRVXnOuysI033rj231VVVVl33XXzf//3fwv8mWydddbJj3/84/Tt2zerr756tthii3Tr1q1eTxaFcluU4/W/+erYSZJ99tknf/7zn3P33Xfn7bffzuuvv5533nlngR4QsNxyy+Xss89Or169cv3112f77bev0z9mzJi89NJLufPOO2vbSv//KqY333yzzu94yZf3sN1www3z1FNPpVOnTnn++edz/fXX57HHHstLL72UqVOnpnHjxunatWseeeSRJJlr/th4441z4YUX1mmb17n169cvs2bNmqsGGiYhGktMs2bNaifOtm3bpnXr1undu3caNWqUAQMGJPlyuf6+++6badOmZaeddsruu++e0047bZ5PZ5rXk61KX7np7X+GbnOCujnbVVRUzLV/TU1N7Qfh/9xnjq/ev21+NG3adK4fGPOq96vmfAj+6vG/+pS8mpqarLDCCnXuAzLHnPelS5cuefzxx/PUU09l5MiRueOOO3LZZZdlyJAh2Xzzzet1DrAs++c//5k2bdqkWbNm8zX2qqqq5jm/zEt9xun8zltFc+OC+M/5J0lOPvnkucLCJFl99dVTU1OTtm3b5ve///1c/csvv/xC1QLltP/++2fTTTdN8uV90Q466KBcfPHFtZcDde/ePRtuuGHt9l/3hNs+ffrkT3/6U04++eT06tWrtn3OWL344ovzve99b679GjdunOeeey4HHXRQttlmm2y88cbZZZddMm3atBxxxBF1tq3vuG3cuHGuv/76jBkzJk8++WSefPLJ3HLLLdljjz2+9jKv/2bOZWK77rrrXPvPz1z6VY0aNZqvG4bPz9OM/3Ob6urqNGnSZIE/kyVf3v7jiCOOyBNPPJGnn346xx13XL7//e8X3p8JGopFMV7/cwzN636sXx07pVIpffv2zWuvvZZdd901P/rRj3LcccfltNNOW+Dz6Nq1a+1lnf/5FOGampocfPDB6dGjx1z7rbLKKvN8ve7du+fRRx/N5ptvnmbNmmWDDTZI586d87e//S0fffRRtt566zqfwf5TTU3NXL9PzuvnwhFHHJFPP/00Z511VrbYYousuuqq83O6lIl7olE2m222WXr37p2bb745TzzxRJLkr3/9a/75z3/mhhtuyNFHH52dd945K6ywQiZNmjTfvwSuu+66Sb68MeMcU6ZMqfMAgPbt22fUqFF19nv11VczderUuVZxLE6tWrVKq1at8vzzz9dpHzVqVL7xjW/kO9/5zjz3a9++faZOnZqZM2fmu9/9bu3X4MGDa6+7v/TSS/P8889nu+22y6mnnpqHHnoo3/72t/PQQw8lyXz/kg/LsgkTJuRPf/pTdt111yTzN/batWs314MGrrvuunl+aCsap1/V0Oatt99+u8578M9//jMXX3xxba3jx49P8+bNa/vXWGONXHjhhXnuueeWWK2wqH31l6EtttgivXr1ytChQ/PUU08l+XLF6lfHxWqrrfa1r3P22Wdn3LhxdZ7++73vfS9VVVUZP358ndd5/PHHM3To0FRWVmbo0KHZdNNNM2jQoBx44IHZcsst8/777yf5+sB8fsbt448/nkGDBmXdddfNoYcemuuvvz5HH3107r///iQL9rlhjTXWyIknnpg77rijzvw1P3PpV3Xs2DHjxo3LJ598Utv2r3/9q3alcH28/PLLtf+eOXNmXn755ay99toL/Jls9OjROeuss/K9730vBx54YK6++uqcddZZeeaZZzJp0qR61wflsjDj9Rvf+EamTp1aZw4aN27cfz3emDFj8vjjj+fSSy9Nv379sttuu+U73/lO3n777YX649/xxx+fVVddNWeccUad9rXXXjv/+te/6pzDBx98kPPOOy+ff/75PF+re/fuefnll/PQQw/V/gFl8803zzPPPFPnfmjt27dPknnOH/8Z5s3Lj3/84/zyl79MixYt8utf/7re58ySJUSjrH75y1+mTZs2Of300/P555+ndevWSb68HOK9997LqFGjcvjhh2fWrFmFl03O8Z3vfCc77rhjfvOb3+Tpp5/O66+/nhNPPLHO/gceeGBeffXV/OY3v8mbb76ZZ599Nv369cu66667RFdpVVRU5KCDDsqNN96Ym266KePGjcsf//jHDBo0KHvttdfXXnr5gx/8IOuss06OOeaYjBw5MuPGjcu5556b4cOH1/4yPW7cuJx++ukZOXJk3nvvvTz44IMZP358unTpkuTL1SCffvppxo4du9CXesHS4IsvvsiHH36YDz/8MO+8804effTRHHzwwVlzzTXTu3fvJPM39g4++OCMHj06F198ccaOHZvHH388V1111VyXQSTF4/SrGtK8dfDBB+eGG27IDTfckLfffjuPPvpozjjjjDRu3DiNGzfObrvtlhVXXDFHHnlkRo8enTfffDMnn3xyHn/88ay99tpLrFZY3Pr165e11lorJ5544lxPgSzSoUOHHH744XX+yNe8efPsvffeufjii3PXXXflnXfeyZ133pnzzz8/3/zmN5N8uWrstddey6hRo/Luu+9m+PDhueSSS5Lkaz8rzc+4raqqyuWXX57rrrsu77zzTv7xj3/kscceq/O5Ifny0vL6hFd77713tthiizoPAZifufSrfvzjH6dly5Y54YQT8uqrr2b06NG1q//qG+5deOGFefTRR/PGG2/kpJNOysyZM7Pvvvsu8GeyFVZYIX/4wx9y/vnnZ9y4cXnttddy3333pU2bNmnZsmW9aoNyW9Dx+v3vfz9TpkzJ1VdfnXfffTd//OMf57ly7au++c1vpqqqKg888EDtnHPMMcfkww8/nO/f++ZlueWWy1lnnTXXg0cOOeSQPPzww7nssssyduzYjBw5MieffHKmTJlSuxKtWbNmee+99zJhwoQkyVprrZU11lgjt912WzbbbLMkX4Zoo0aNyocffpitt966drttttkmZ5xxRh577LGMHTs2gwYNyp/+9Kf/+iCWr2ratGl++9vf5rHHHsvdd9+9wOfP4udyTsqqSZMm+e1vf5v9998/AwcOzKmnnpqTTz451113XS6++OKsttpq2XnnnbP66qvnxRdfnO/XPffcc3Peeefl2GOPTU1NTfbaa698/PHHtf1dunTJ4MGDc8kll2SPPfbICiuskO233z7HH3/8f12SuzgcfPDBady4cYYNG5azzz47rVu3ziGHHJJf/OIXX7tPo0aNcs011+T888/Psccem2nTpqVdu3a57LLLan+ZPuOMM3LuuefmhBNOyCeffJI11lgj/fr1q30S6g477JDbbrstu+22W2688cY6l5/Asuiaa67JNddck+TLXxZbt26dHXbYIQcddFCaNWuWZP7G3jrrrJMrrrgil156aYYMGZJVVlklvXr1muejzIvG6Vc1pHnroIMOSpMmTXLDDTfk3HPPTatWrbLnnnvm2GOPTfJlEHDjjTfmvPPOy8EHH5zq6uqss846GTp0qBCNpUqTJk1y/vnn56c//Wn69++fIUOG1CvUOfTQQ/Poo4/W3nMo+fKSy5VXXjmXXnppJk6cmNatW+fII4/MoYcemiQ5+uij89FHH9XOKWuttVbOOuusnHDCCXnppZe+dmVq0bjdcsstc+aZZ+aaa67JwIED07Rp02yzzTY56aSTkiQtW7ZMz549c95552XcuHE59dRT5/s8f/e739Wu6E3mby79qsaNG2fIkCH5zW9+k5/97GdZccUV07dv37z88sv1nv+OOuqoXHDBBXn33XfTqVOnXHvttbX3WluQz2RrrbVWLrvssgwaNCh/+MMfUllZmc022yyDBw+u9y1AoCFYkPG6ySab5Nhjj82NN96Yyy+/PF27dk3//v3Tv3//rz3OaqutlnPOOSeXXXZZbrrppqyyyirp1q1bDjzwwPzpT39aqNVocy7rvOGGG2rbdtxxxwwcODBXXXVVrrrqqqy44orZdtttawP55MsQsX///tltt90ycuTINGrUKNtuu22GDRtWG6J16tQpyy+/fLp06ZIVVlihdt+BAwfmoosuyqmnnpopU6Zk7bXXzmWXXVavpzhvvvnm2XPPPWsv6/y6y0wpr4rSwt4oBQAAYDF5991389Zbb2Wrrbaqbfvggw+y9dZb56abbqrzsAAAWJz8eQQAAGiwZsyYkUMPPTRDhw7NO++8kzFjxuS0005LmzZtrKQHYImyEg0AAGjQHnzwwVx55ZUZO3ZsmjZtms033zwnnnhivvWtb5W7NACWIUI0AAAAACjgck4AAAAAKCBEAwAAAIACQjQAAAAAKCBEAwAAAIACQjQAAAAAKCBEAwBoYHr16pUOHTpk7733/tptjj322HTo0CEnnXTSQh3rmWeeSYcOHfLMM8/M9z7vvvtuOnTokBEjRizUsQEA/pcI0QAAGqCKioqMHj0677///lx906ZNy1/+8pclXxQAwDJMiAYA0ACtt956adKkSR588MG5+v785z+nSZMmWW211cpQGQDAskmIBgDQAC2//PLZZptt8sADD8zVd//992fHHXdMVVVVbduMGTNy+eWXZ8cdd8wGG2yQHXbYIVdffXVqamrq7HvLLbfkRz/6UTp16pT99tsv48ePn+v1x48fn+OOOy6bbLJJNtxwwxxwwAEZM2bM19ZaU1OTSy65JN27d8/666+f7t2756KLLsqsWbMW4h0AAGhYhGgAAA3UzjvvnBdffLFO0DV16tQ88cQT+fGPf1zbViqV0rdv3wwZMiQ/+clPcuWVV2bHHXfMxRdfnNNPP712uxtvvDGnn356fvCDH+SKK67IhhtumNNOO63OMT/++OPsvffe+ec//5nTTjstF154YWpqarLvvvvmzTffnGedgwcPzk033ZQjjjgi11xzTX7+859nyJAhufLKKxfxOwIAUD5VxZsAAFAO3bp1y/LLL58HH3wwBx10UJLkkUceycorr5yNNtqodrsnnngiTz/9dM4///zstttuSZItt9wyTZs2zSWXXJIDDjgg7dq1yxVXXJEf/ehHOfXUU5MkW221VaZOnZpbbrml9rWGDRuWTz75JDfffHPWWGONJMnWW2+dnXfeOZdcckkuvfTSuep89tlns95666Vnz55Jkk022STLLbdcVlhhhcXzxgAAlIGVaAAADVTTpk3TvXv3Opd03nfffdl5551TUVFR2/bss8+mUaNG2XnnnevsPydQe+aZZ/Kvf/0rkyZNynbbbVdnm5122qnO9yNHjsw666yT1VZbLbNnz87s2bNTWVmZrbfeOk8//fQ869x0003z9NNPZ5999sm1116bN998M/vtt1/22GOPhTl9AIAGxUo0AIAGbKeddsoRRxyRd999N82aNcvIkSNzzDHH1Nnm008/TcuWLevcIy1JVllllSTJZ599lk8//TRJsvLKK89zmzk++eSTjBs3Luutt94865k2bdpcbQcffHCaNWuW4cOH59xzz80555yT9u3b51e/+lU233zzep0vAEBDJUQDAGjAtt566zRv3jwPPfRQmjdvnjXXXDPrr79+nW1WXHHFTJ48ObNnz64TpE2cODFJ0rJly7Rs2TJJMmnSpDr7fvLJJ3W+b968eTbZZJOceOKJ86yncePGc7VVVlZm3333zb777ptJkybl8ccfz5VXXpmjjjoqTz/99Dz3AQD4X+NyTgCABqxx48bZbrvt8vDDD+eBBx7ILrvsMtc2m2yySaqrq3P//ffXab/nnnuSJBtttFHatGmT1VdfPQ8++GCdbR577LG5Xmvs2LFp27ZtNthgg9qve+65J7fffnsaNWo01/H33nvv/O53v0uStGrVKnvuuWf23XfffPbZZ5k6depCnT8AQENhJRoAQAO38847p0+fPqmsrKx9KMBXbb311tl0001z+umnZ+LEiVl33XXz7LPPZvDgwenRo0fWWmutJEm/fv1y/PHH59RTT82OO+6Y0aNH5+abb67zWgceeGDuvvvuHHjggTnooIPSsmXL3H///bntttty8sknz7O+rl275pprrsk3v/nNdOnSJR988EGuvfbabLLJJnNdPgoA8L9KiAYA0MBtscUWadGiRVZfffW0a9durv6KiopcddVVufTSS3P99dfn448/zpprrpljjz02vXv3rt3uxz/+cSorK3PFFVfk7rvvTvv27fOb3/wmxx13XO02q622Wm655ZZceOGFGTBgQGbMmJE2bdrkzDPPzE9+8pN51vfLX/4yjRs3zvDhw3P55ZenefPm6d69e44//vhF/2YAAJRJRalUKpW7CAAAAABoyNwTDQAAAAAKCNEAAAAAoIAQDQAAAAAKCNEAAAAAoIAQDQAAAAAKCNEAAAAAoIAQDQAAAAAKCNEAAAAAoIAQDQAAAAAKCNEAAAAAoIAQDQAAAAAK/D87gG48XTJixAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "\n",
    "sns.barplot(models,scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

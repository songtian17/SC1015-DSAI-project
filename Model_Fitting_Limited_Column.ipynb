{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 4 types of model to predict if the person will have prediabetes/diabetes or not, with the 4 models being Random Forest, Decision Tree, K Nearest Neighbors and Neural Network. This set uses only some seleceted columns to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  BMI  Smoker  Stroke  \\\n",
       "0                1       1         1   30       1       0   \n",
       "1                1       0         0   25       1       0   \n",
       "2                1       1         1   28       0       0   \n",
       "3                1       0         0   23       1       0   \n",
       "4                1       1         0   27       0       0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  AnyHealthcare  \\\n",
       "0                     1             0       1        1  ...              1   \n",
       "1                     0             1       1        1  ...              1   \n",
       "2                     0             0       0        1  ...              1   \n",
       "3                     0             1       0        0  ...              1   \n",
       "4                     0             1       1        1  ...              1   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  \\\n",
       "0            0        5        30        30         1    0    9          5   \n",
       "1            0        3         0         0         0    1   13          6   \n",
       "2            0        4         0         0         1    0   11          4   \n",
       "3            0        2         0         0         0    1    7          5   \n",
       "4            0        1         0         0         0    0   13          5   \n",
       "\n",
       "   Income  \n",
       "0       1  \n",
       "1       8  \n",
       "2       6  \n",
       "3       6  \n",
       "4       4  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the balanced data\n",
    "df = pd.read_csv('balanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df[[\"HighBP\", \"HighChol\", \"BMI\", \"HeartDiseaseorAttack\", \"GenHlth\", \"PhysHlth\", \"DiffWalk\", \"Age\", \"Income\"]]\n",
    "response = df[\"Diabetes_binary\"]\n",
    "pred_train, pred_test, res_train, res_test = train_test_split(predictors, response, test_size = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a machine learning algorithm that creates multiple decision trees to make predictions on a dataset.\n",
    "It combines the results from several decision trees to improve accuracy and reduce overfitting.\n",
    "Each decision tree is created with a random sample with replacement from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Random Forest is: 69.27 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "max_accuracy = 0\n",
    "\n",
    "# Loop the Classifier in order to find the state with the highest accuracy\n",
    "for x in range(200):\n",
    "    rf = RandomForestClassifier(random_state=x)\n",
    "    rf.fit(pred_train,res_train)\n",
    "    res_pred_rf = rf.predict(pred_test)\n",
    "    current_accuracy = round(accuracy_score(res_pred_rf,res_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "rf = RandomForestClassifier(random_state=best_x)\n",
    "rf.fit(pred_train,res_train)\n",
    "res_pred_rf = rf.predict(pred_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "score_rf = round(accuracy_score(res_pred_rf,res_test)*100,2)\n",
    "print(\"The accuracy score achieved using Random Forest is: \"+str(score_rf)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is a binary classification method used to classify an output based on its input through the use of nodes and branches. The nodes contains information of the input and the paths represent the possible outcome to the input, depending on its classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 65.07 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "max_accuracy = 0\n",
    "\n",
    "# As with the Random Forest model, loop the Classifier function to get the state with the best accuracy\n",
    "for x in range(20):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(pred_train,res_train)\n",
    "    res_pred_dt = dt.predict(pred_test)\n",
    "    current_accuracy = round(accuracy_score(res_pred_dt,res_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(pred_train,res_train)\n",
    "res_pred_dt = dt.predict(pred_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "score_dt = round(accuracy_score(res_pred_dt,res_test)*100,2)\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors is a classification method that classifies data to the nearest neighbour in proximity to the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 69.88 %\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(pred_train,res_train)\n",
    "res_pred_knn=knn.predict(pred_test)\n",
    "score_knn = round(accuracy_score(res_pred_knn,res_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network is a machine learning model based on biological neural network. It takes inputs, runs it through several hidden layers in order to create the desired outcome."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary modules if they are not in your libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1972/1972 [==============================] - 2s 726us/step - loss: 0.5917 - accuracy: 0.6862\n",
      "Epoch 2/300\n",
      "1972/1972 [==============================] - 1s 706us/step - loss: 0.5666 - accuracy: 0.7098\n",
      "Epoch 3/300\n",
      "1972/1972 [==============================] - 1s 701us/step - loss: 0.5595 - accuracy: 0.7144\n",
      "Epoch 4/300\n",
      "1972/1972 [==============================] - 1s 691us/step - loss: 0.5550 - accuracy: 0.7177\n",
      "Epoch 5/300\n",
      "1972/1972 [==============================] - 1s 731us/step - loss: 0.5526 - accuracy: 0.7196\n",
      "Epoch 6/300\n",
      "1972/1972 [==============================] - 1s 735us/step - loss: 0.5505 - accuracy: 0.7185\n",
      "Epoch 7/300\n",
      "1972/1972 [==============================] - 1s 683us/step - loss: 0.5497 - accuracy: 0.7209\n",
      "Epoch 8/300\n",
      "1972/1972 [==============================] - 1s 711us/step - loss: 0.5484 - accuracy: 0.7216\n",
      "Epoch 9/300\n",
      "1972/1972 [==============================] - 1s 680us/step - loss: 0.5482 - accuracy: 0.7216\n",
      "Epoch 10/300\n",
      "1972/1972 [==============================] - 1s 656us/step - loss: 0.5470 - accuracy: 0.7227\n",
      "Epoch 11/300\n",
      "1972/1972 [==============================] - 1s 680us/step - loss: 0.5477 - accuracy: 0.7215\n",
      "Epoch 12/300\n",
      "1972/1972 [==============================] - 1s 698us/step - loss: 0.5473 - accuracy: 0.7212\n",
      "Epoch 13/300\n",
      "1972/1972 [==============================] - 1s 699us/step - loss: 0.5469 - accuracy: 0.7234\n",
      "Epoch 14/300\n",
      "1972/1972 [==============================] - 1s 744us/step - loss: 0.5467 - accuracy: 0.7214\n",
      "Epoch 15/300\n",
      "1972/1972 [==============================] - 1s 741us/step - loss: 0.5464 - accuracy: 0.7227\n",
      "Epoch 16/300\n",
      "1972/1972 [==============================] - 1s 714us/step - loss: 0.5463 - accuracy: 0.7235\n",
      "Epoch 17/300\n",
      "1972/1972 [==============================] - 1s 660us/step - loss: 0.5457 - accuracy: 0.7234\n",
      "Epoch 18/300\n",
      "1972/1972 [==============================] - 1s 683us/step - loss: 0.5456 - accuracy: 0.7225\n",
      "Epoch 19/300\n",
      "1972/1972 [==============================] - 1s 714us/step - loss: 0.5457 - accuracy: 0.7245\n",
      "Epoch 20/300\n",
      "1972/1972 [==============================] - 1s 736us/step - loss: 0.5456 - accuracy: 0.7231\n",
      "Epoch 21/300\n",
      "1972/1972 [==============================] - 2s 782us/step - loss: 0.5450 - accuracy: 0.7241\n",
      "Epoch 22/300\n",
      "1972/1972 [==============================] - 1s 731us/step - loss: 0.5454 - accuracy: 0.7237\n",
      "Epoch 23/300\n",
      "1972/1972 [==============================] - 1s 716us/step - loss: 0.5456 - accuracy: 0.7234\n",
      "Epoch 24/300\n",
      "1972/1972 [==============================] - 1s 654us/step - loss: 0.5448 - accuracy: 0.7244\n",
      "Epoch 25/300\n",
      "1972/1972 [==============================] - 1s 717us/step - loss: 0.5449 - accuracy: 0.7238\n",
      "Epoch 26/300\n",
      "1972/1972 [==============================] - 2s 783us/step - loss: 0.5447 - accuracy: 0.7241\n",
      "Epoch 27/300\n",
      "1972/1972 [==============================] - 1s 757us/step - loss: 0.5449 - accuracy: 0.7234\n",
      "Epoch 28/300\n",
      "1972/1972 [==============================] - 2s 765us/step - loss: 0.5448 - accuracy: 0.7237\n",
      "Epoch 29/300\n",
      "1972/1972 [==============================] - 1s 665us/step - loss: 0.5451 - accuracy: 0.7228\n",
      "Epoch 30/300\n",
      "1972/1972 [==============================] - 1s 683us/step - loss: 0.5444 - accuracy: 0.7231\n",
      "Epoch 31/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5446 - accuracy: 0.7246\n",
      "Epoch 32/300\n",
      "1972/1972 [==============================] - 2s 822us/step - loss: 0.5447 - accuracy: 0.7240\n",
      "Epoch 33/300\n",
      "1972/1972 [==============================] - 1s 730us/step - loss: 0.5452 - accuracy: 0.7235\n",
      "Epoch 34/300\n",
      "1972/1972 [==============================] - 1s 725us/step - loss: 0.5440 - accuracy: 0.7245\n",
      "Epoch 35/300\n",
      "1972/1972 [==============================] - 1s 711us/step - loss: 0.5440 - accuracy: 0.7242\n",
      "Epoch 36/300\n",
      "1972/1972 [==============================] - 2s 810us/step - loss: 0.5443 - accuracy: 0.7251\n",
      "Epoch 37/300\n",
      "1972/1972 [==============================] - 1s 756us/step - loss: 0.5444 - accuracy: 0.7231\n",
      "Epoch 38/300\n",
      "1972/1972 [==============================] - 1s 695us/step - loss: 0.5436 - accuracy: 0.7246\n",
      "Epoch 39/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5437 - accuracy: 0.7243\n",
      "Epoch 40/300\n",
      "1972/1972 [==============================] - 1s 675us/step - loss: 0.5440 - accuracy: 0.7238\n",
      "Epoch 41/300\n",
      "1972/1972 [==============================] - 1s 746us/step - loss: 0.5439 - accuracy: 0.7249\n",
      "Epoch 42/300\n",
      "1972/1972 [==============================] - 1s 759us/step - loss: 0.5438 - accuracy: 0.7230\n",
      "Epoch 43/300\n",
      "1972/1972 [==============================] - 1s 662us/step - loss: 0.5437 - accuracy: 0.7251\n",
      "Epoch 44/300\n",
      "1972/1972 [==============================] - 1s 666us/step - loss: 0.5435 - accuracy: 0.7253\n",
      "Epoch 45/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5435 - accuracy: 0.7259\n",
      "Epoch 46/300\n",
      "1972/1972 [==============================] - 1s 613us/step - loss: 0.5434 - accuracy: 0.7249\n",
      "Epoch 47/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5429 - accuracy: 0.7252\n",
      "Epoch 48/300\n",
      "1972/1972 [==============================] - 1s 654us/step - loss: 0.5439 - accuracy: 0.7236\n",
      "Epoch 49/300\n",
      "1972/1972 [==============================] - 1s 604us/step - loss: 0.5436 - accuracy: 0.7250\n",
      "Epoch 50/300\n",
      "1972/1972 [==============================] - 1s 627us/step - loss: 0.5434 - accuracy: 0.7241\n",
      "Epoch 51/300\n",
      "1972/1972 [==============================] - 1s 640us/step - loss: 0.5431 - accuracy: 0.7254\n",
      "Epoch 52/300\n",
      "1972/1972 [==============================] - 1s 643us/step - loss: 0.5432 - accuracy: 0.7243\n",
      "Epoch 53/300\n",
      "1972/1972 [==============================] - 1s 635us/step - loss: 0.5429 - accuracy: 0.7253\n",
      "Epoch 54/300\n",
      "1972/1972 [==============================] - 1s 605us/step - loss: 0.5433 - accuracy: 0.7246\n",
      "Epoch 55/300\n",
      "1972/1972 [==============================] - 1s 613us/step - loss: 0.5432 - accuracy: 0.7250\n",
      "Epoch 56/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5431 - accuracy: 0.7247\n",
      "Epoch 57/300\n",
      "1972/1972 [==============================] - 1s 675us/step - loss: 0.5430 - accuracy: 0.7243\n",
      "Epoch 58/300\n",
      "1972/1972 [==============================] - 1s 681us/step - loss: 0.5429 - accuracy: 0.7240\n",
      "Epoch 59/300\n",
      "1972/1972 [==============================] - 1s 682us/step - loss: 0.5425 - accuracy: 0.7249\n",
      "Epoch 60/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5429 - accuracy: 0.7251\n",
      "Epoch 61/300\n",
      "1972/1972 [==============================] - 1s 662us/step - loss: 0.5431 - accuracy: 0.7242\n",
      "Epoch 62/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5430 - accuracy: 0.7250\n",
      "Epoch 63/300\n",
      "1972/1972 [==============================] - 1s 638us/step - loss: 0.5426 - accuracy: 0.7247\n",
      "Epoch 64/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5425 - accuracy: 0.7247\n",
      "Epoch 65/300\n",
      "1972/1972 [==============================] - 1s 729us/step - loss: 0.5427 - accuracy: 0.7251\n",
      "Epoch 66/300\n",
      "1972/1972 [==============================] - 1s 718us/step - loss: 0.5424 - accuracy: 0.7262\n",
      "Epoch 67/300\n",
      "1972/1972 [==============================] - 1s 706us/step - loss: 0.5424 - accuracy: 0.7254\n",
      "Epoch 68/300\n",
      "1972/1972 [==============================] - 1s 684us/step - loss: 0.5427 - accuracy: 0.7252\n",
      "Epoch 69/300\n",
      "1972/1972 [==============================] - 1s 709us/step - loss: 0.5428 - accuracy: 0.7252\n",
      "Epoch 70/300\n",
      "1972/1972 [==============================] - 1s 711us/step - loss: 0.5424 - accuracy: 0.7243\n",
      "Epoch 71/300\n",
      "1972/1972 [==============================] - 1s 682us/step - loss: 0.5422 - accuracy: 0.7246\n",
      "Epoch 72/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5422 - accuracy: 0.7256\n",
      "Epoch 73/300\n",
      "1972/1972 [==============================] - 1s 644us/step - loss: 0.5423 - accuracy: 0.7265\n",
      "Epoch 74/300\n",
      "1972/1972 [==============================] - 1s 630us/step - loss: 0.5420 - accuracy: 0.7254\n",
      "Epoch 75/300\n",
      "1972/1972 [==============================] - 1s 640us/step - loss: 0.5426 - accuracy: 0.7252\n",
      "Epoch 76/300\n",
      "1972/1972 [==============================] - 1s 629us/step - loss: 0.5421 - accuracy: 0.7254\n",
      "Epoch 77/300\n",
      "1972/1972 [==============================] - 1s 689us/step - loss: 0.5423 - accuracy: 0.7258\n",
      "Epoch 78/300\n",
      "1972/1972 [==============================] - 1s 651us/step - loss: 0.5418 - accuracy: 0.7252\n",
      "Epoch 79/300\n",
      "1972/1972 [==============================] - 1s 709us/step - loss: 0.5416 - accuracy: 0.7249\n",
      "Epoch 80/300\n",
      "1972/1972 [==============================] - 1s 622us/step - loss: 0.5418 - accuracy: 0.7267\n",
      "Epoch 81/300\n",
      "1972/1972 [==============================] - 1s 685us/step - loss: 0.5416 - accuracy: 0.7247\n",
      "Epoch 82/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5418 - accuracy: 0.7261\n",
      "Epoch 83/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5417 - accuracy: 0.7249\n",
      "Epoch 84/300\n",
      "1972/1972 [==============================] - 1s 711us/step - loss: 0.5414 - accuracy: 0.7265\n",
      "Epoch 85/300\n",
      "1972/1972 [==============================] - 1s 721us/step - loss: 0.5416 - accuracy: 0.7254\n",
      "Epoch 86/300\n",
      "1972/1972 [==============================] - 1s 667us/step - loss: 0.5419 - accuracy: 0.7254\n",
      "Epoch 87/300\n",
      "1972/1972 [==============================] - 1s 690us/step - loss: 0.5415 - accuracy: 0.7269\n",
      "Epoch 88/300\n",
      "1972/1972 [==============================] - 1s 668us/step - loss: 0.5416 - accuracy: 0.7251\n",
      "Epoch 89/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5415 - accuracy: 0.7253\n",
      "Epoch 90/300\n",
      "1972/1972 [==============================] - 1s 743us/step - loss: 0.5413 - accuracy: 0.7259\n",
      "Epoch 91/300\n",
      "1972/1972 [==============================] - 1s 703us/step - loss: 0.5410 - accuracy: 0.7266\n",
      "Epoch 92/300\n",
      "1972/1972 [==============================] - 1s 687us/step - loss: 0.5413 - accuracy: 0.7256\n",
      "Epoch 93/300\n",
      "1972/1972 [==============================] - 1s 692us/step - loss: 0.5411 - accuracy: 0.7259\n",
      "Epoch 94/300\n",
      "1972/1972 [==============================] - 1s 737us/step - loss: 0.5412 - accuracy: 0.7256\n",
      "Epoch 95/300\n",
      "1972/1972 [==============================] - 1s 716us/step - loss: 0.5410 - accuracy: 0.7266\n",
      "Epoch 96/300\n",
      "1972/1972 [==============================] - 1s 727us/step - loss: 0.5411 - accuracy: 0.7254\n",
      "Epoch 97/300\n",
      "1972/1972 [==============================] - 2s 765us/step - loss: 0.5409 - accuracy: 0.7251\n",
      "Epoch 98/300\n",
      "1972/1972 [==============================] - 1s 740us/step - loss: 0.5409 - accuracy: 0.7254\n",
      "Epoch 99/300\n",
      "1972/1972 [==============================] - 2s 812us/step - loss: 0.5408 - accuracy: 0.7264\n",
      "Epoch 100/300\n",
      "1972/1972 [==============================] - 2s 933us/step - loss: 0.5406 - accuracy: 0.7266\n",
      "Epoch 101/300\n",
      "1972/1972 [==============================] - 2s 925us/step - loss: 0.5405 - accuracy: 0.7260\n",
      "Epoch 102/300\n",
      "1972/1972 [==============================] - 2s 802us/step - loss: 0.5402 - accuracy: 0.7266\n",
      "Epoch 103/300\n",
      "1972/1972 [==============================] - 2s 826us/step - loss: 0.5405 - accuracy: 0.7261\n",
      "Epoch 104/300\n",
      "1972/1972 [==============================] - 1s 727us/step - loss: 0.5405 - accuracy: 0.7258\n",
      "Epoch 105/300\n",
      "1972/1972 [==============================] - 1s 708us/step - loss: 0.5403 - accuracy: 0.7262\n",
      "Epoch 106/300\n",
      "1972/1972 [==============================] - 2s 793us/step - loss: 0.5405 - accuracy: 0.7267\n",
      "Epoch 107/300\n",
      "1972/1972 [==============================] - 2s 761us/step - loss: 0.5404 - accuracy: 0.7264\n",
      "Epoch 108/300\n",
      "1972/1972 [==============================] - 2s 785us/step - loss: 0.5403 - accuracy: 0.7263\n",
      "Epoch 109/300\n",
      "1972/1972 [==============================] - 2s 776us/step - loss: 0.5404 - accuracy: 0.7260\n",
      "Epoch 110/300\n",
      "1972/1972 [==============================] - 1s 729us/step - loss: 0.5400 - accuracy: 0.7270\n",
      "Epoch 111/300\n",
      "1972/1972 [==============================] - 1s 682us/step - loss: 0.5403 - accuracy: 0.7264\n",
      "Epoch 112/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5400 - accuracy: 0.7270\n",
      "Epoch 113/300\n",
      "1972/1972 [==============================] - 1s 720us/step - loss: 0.5402 - accuracy: 0.7261\n",
      "Epoch 114/300\n",
      "1972/1972 [==============================] - 1s 719us/step - loss: 0.5399 - accuracy: 0.7264\n",
      "Epoch 115/300\n",
      "1972/1972 [==============================] - 1s 758us/step - loss: 0.5400 - accuracy: 0.7259\n",
      "Epoch 116/300\n",
      "1972/1972 [==============================] - 2s 764us/step - loss: 0.5399 - accuracy: 0.7275\n",
      "Epoch 117/300\n",
      "1972/1972 [==============================] - 1s 745us/step - loss: 0.5399 - accuracy: 0.7268\n",
      "Epoch 118/300\n",
      "1972/1972 [==============================] - 1s 717us/step - loss: 0.5397 - accuracy: 0.7274\n",
      "Epoch 119/300\n",
      "1972/1972 [==============================] - 1s 758us/step - loss: 0.5398 - accuracy: 0.7266\n",
      "Epoch 120/300\n",
      "1972/1972 [==============================] - 2s 821us/step - loss: 0.5395 - accuracy: 0.7273\n",
      "Epoch 121/300\n",
      "1972/1972 [==============================] - 1s 758us/step - loss: 0.5397 - accuracy: 0.7274\n",
      "Epoch 122/300\n",
      "1972/1972 [==============================] - 1s 727us/step - loss: 0.5396 - accuracy: 0.7269\n",
      "Epoch 123/300\n",
      "1972/1972 [==============================] - 1s 681us/step - loss: 0.5397 - accuracy: 0.7271\n",
      "Epoch 124/300\n",
      "1972/1972 [==============================] - 1s 690us/step - loss: 0.5398 - accuracy: 0.7272\n",
      "Epoch 125/300\n",
      "1972/1972 [==============================] - 1s 675us/step - loss: 0.5396 - accuracy: 0.7269\n",
      "Epoch 126/300\n",
      "1972/1972 [==============================] - 1s 695us/step - loss: 0.5394 - accuracy: 0.7279\n",
      "Epoch 127/300\n",
      "1972/1972 [==============================] - 2s 779us/step - loss: 0.5395 - accuracy: 0.7279\n",
      "Epoch 128/300\n",
      "1972/1972 [==============================] - 2s 787us/step - loss: 0.5396 - accuracy: 0.7276\n",
      "Epoch 129/300\n",
      "1972/1972 [==============================] - 1s 740us/step - loss: 0.5393 - accuracy: 0.7278\n",
      "Epoch 130/300\n",
      "1972/1972 [==============================] - 1s 725us/step - loss: 0.5397 - accuracy: 0.7269\n",
      "Epoch 131/300\n",
      "1972/1972 [==============================] - 1s 660us/step - loss: 0.5393 - accuracy: 0.7283\n",
      "Epoch 132/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5398 - accuracy: 0.7272\n",
      "Epoch 133/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5394 - accuracy: 0.7275\n",
      "Epoch 134/300\n",
      "1972/1972 [==============================] - 1s 754us/step - loss: 0.5393 - accuracy: 0.7263\n",
      "Epoch 135/300\n",
      "1972/1972 [==============================] - 1s 708us/step - loss: 0.5396 - accuracy: 0.7277\n",
      "Epoch 136/300\n",
      "1972/1972 [==============================] - 1s 753us/step - loss: 0.5397 - accuracy: 0.7269\n",
      "Epoch 137/300\n",
      "1972/1972 [==============================] - 1s 613us/step - loss: 0.5395 - accuracy: 0.7274\n",
      "Epoch 138/300\n",
      "1972/1972 [==============================] - 1s 688us/step - loss: 0.5394 - accuracy: 0.7269\n",
      "Epoch 139/300\n",
      "1972/1972 [==============================] - 1s 731us/step - loss: 0.5393 - accuracy: 0.7270\n",
      "Epoch 140/300\n",
      "1972/1972 [==============================] - 1s 726us/step - loss: 0.5391 - accuracy: 0.7276\n",
      "Epoch 141/300\n",
      "1972/1972 [==============================] - 1s 693us/step - loss: 0.5395 - accuracy: 0.7270\n",
      "Epoch 142/300\n",
      "1972/1972 [==============================] - 1s 682us/step - loss: 0.5392 - accuracy: 0.7265\n",
      "Epoch 143/300\n",
      "1972/1972 [==============================] - 1s 705us/step - loss: 0.5391 - accuracy: 0.7276\n",
      "Epoch 144/300\n",
      "1972/1972 [==============================] - 1s 638us/step - loss: 0.5395 - accuracy: 0.7266\n",
      "Epoch 145/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5394 - accuracy: 0.7264\n",
      "Epoch 146/300\n",
      "1972/1972 [==============================] - 1s 611us/step - loss: 0.5391 - accuracy: 0.7277\n",
      "Epoch 147/300\n",
      "1972/1972 [==============================] - 1s 625us/step - loss: 0.5389 - accuracy: 0.7266\n",
      "Epoch 148/300\n",
      "1972/1972 [==============================] - 1s 641us/step - loss: 0.5392 - accuracy: 0.7279\n",
      "Epoch 149/300\n",
      "1972/1972 [==============================] - 1s 642us/step - loss: 0.5393 - accuracy: 0.7271\n",
      "Epoch 150/300\n",
      "1972/1972 [==============================] - 1s 614us/step - loss: 0.5387 - accuracy: 0.7271\n",
      "Epoch 151/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5391 - accuracy: 0.7278\n",
      "Epoch 152/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5390 - accuracy: 0.7281\n",
      "Epoch 153/300\n",
      "1972/1972 [==============================] - 1s 644us/step - loss: 0.5393 - accuracy: 0.7285\n",
      "Epoch 154/300\n",
      "1972/1972 [==============================] - 1s 633us/step - loss: 0.5390 - accuracy: 0.7279\n",
      "Epoch 155/300\n",
      "1972/1972 [==============================] - 1s 650us/step - loss: 0.5392 - accuracy: 0.7270\n",
      "Epoch 156/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5391 - accuracy: 0.7275\n",
      "Epoch 157/300\n",
      "1972/1972 [==============================] - 1s 645us/step - loss: 0.5389 - accuracy: 0.7268\n",
      "Epoch 158/300\n",
      "1972/1972 [==============================] - 1s 645us/step - loss: 0.5393 - accuracy: 0.7272\n",
      "Epoch 159/300\n",
      "1972/1972 [==============================] - 1s 667us/step - loss: 0.5389 - accuracy: 0.7282\n",
      "Epoch 160/300\n",
      "1972/1972 [==============================] - 1s 667us/step - loss: 0.5389 - accuracy: 0.7276\n",
      "Epoch 161/300\n",
      "1972/1972 [==============================] - 1s 733us/step - loss: 0.5391 - accuracy: 0.7280\n",
      "Epoch 162/300\n",
      "1972/1972 [==============================] - 1s 676us/step - loss: 0.5390 - accuracy: 0.7288\n",
      "Epoch 163/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5391 - accuracy: 0.7281\n",
      "Epoch 164/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5391 - accuracy: 0.7274\n",
      "Epoch 165/300\n",
      "1972/1972 [==============================] - 1s 702us/step - loss: 0.5387 - accuracy: 0.7281\n",
      "Epoch 166/300\n",
      "1972/1972 [==============================] - 2s 762us/step - loss: 0.5390 - accuracy: 0.7274\n",
      "Epoch 167/300\n",
      "1972/1972 [==============================] - 1s 688us/step - loss: 0.5392 - accuracy: 0.7281\n",
      "Epoch 168/300\n",
      "1972/1972 [==============================] - 1s 756us/step - loss: 0.5390 - accuracy: 0.7281\n",
      "Epoch 169/300\n",
      "1972/1972 [==============================] - 1s 686us/step - loss: 0.5392 - accuracy: 0.7275\n",
      "Epoch 170/300\n",
      "1972/1972 [==============================] - 1s 626us/step - loss: 0.5389 - accuracy: 0.7280\n",
      "Epoch 171/300\n",
      "1972/1972 [==============================] - 1s 641us/step - loss: 0.5390 - accuracy: 0.7283\n",
      "Epoch 172/300\n",
      "1972/1972 [==============================] - 1s 630us/step - loss: 0.5391 - accuracy: 0.7270\n",
      "Epoch 173/300\n",
      "1972/1972 [==============================] - 1s 669us/step - loss: 0.5391 - accuracy: 0.7276\n",
      "Epoch 174/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5387 - accuracy: 0.7280\n",
      "Epoch 175/300\n",
      "1972/1972 [==============================] - 1s 723us/step - loss: 0.5390 - accuracy: 0.7269\n",
      "Epoch 176/300\n",
      "1972/1972 [==============================] - 1s 667us/step - loss: 0.5391 - accuracy: 0.7279\n",
      "Epoch 177/300\n",
      "1972/1972 [==============================] - 1s 646us/step - loss: 0.5390 - accuracy: 0.7275\n",
      "Epoch 178/300\n",
      "1972/1972 [==============================] - 1s 646us/step - loss: 0.5388 - accuracy: 0.7281\n",
      "Epoch 179/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5392 - accuracy: 0.7272\n",
      "Epoch 180/300\n",
      "1972/1972 [==============================] - 1s 632us/step - loss: 0.5390 - accuracy: 0.7274\n",
      "Epoch 181/300\n",
      "1972/1972 [==============================] - 1s 660us/step - loss: 0.5386 - accuracy: 0.7287\n",
      "Epoch 182/300\n",
      "1972/1972 [==============================] - 1s 638us/step - loss: 0.5391 - accuracy: 0.7282\n",
      "Epoch 183/300\n",
      "1972/1972 [==============================] - 1s 649us/step - loss: 0.5387 - accuracy: 0.7292\n",
      "Epoch 184/300\n",
      "1972/1972 [==============================] - 1s 621us/step - loss: 0.5389 - accuracy: 0.7272\n",
      "Epoch 185/300\n",
      "1972/1972 [==============================] - 1s 640us/step - loss: 0.5390 - accuracy: 0.7279\n",
      "Epoch 186/300\n",
      "1972/1972 [==============================] - 1s 622us/step - loss: 0.5391 - accuracy: 0.7279\n",
      "Epoch 187/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5388 - accuracy: 0.7285\n",
      "Epoch 188/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5390 - accuracy: 0.7277\n",
      "Epoch 189/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5389 - accuracy: 0.7285\n",
      "Epoch 190/300\n",
      "1972/1972 [==============================] - 1s 636us/step - loss: 0.5387 - accuracy: 0.7283\n",
      "Epoch 191/300\n",
      "1972/1972 [==============================] - 1s 649us/step - loss: 0.5386 - accuracy: 0.7274\n",
      "Epoch 192/300\n",
      "1972/1972 [==============================] - 1s 644us/step - loss: 0.5390 - accuracy: 0.7269\n",
      "Epoch 193/300\n",
      "1972/1972 [==============================] - 1s 663us/step - loss: 0.5388 - accuracy: 0.7277\n",
      "Epoch 194/300\n",
      "1972/1972 [==============================] - 1s 675us/step - loss: 0.5390 - accuracy: 0.7277\n",
      "Epoch 195/300\n",
      "1972/1972 [==============================] - 1s 625us/step - loss: 0.5389 - accuracy: 0.7272\n",
      "Epoch 196/300\n",
      "1972/1972 [==============================] - 1s 651us/step - loss: 0.5389 - accuracy: 0.7275\n",
      "Epoch 197/300\n",
      "1972/1972 [==============================] - 1s 638us/step - loss: 0.5389 - accuracy: 0.7273\n",
      "Epoch 198/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5387 - accuracy: 0.7282\n",
      "Epoch 199/300\n",
      "1972/1972 [==============================] - 1s 662us/step - loss: 0.5385 - accuracy: 0.7281\n",
      "Epoch 200/300\n",
      "1972/1972 [==============================] - 1s 662us/step - loss: 0.5388 - accuracy: 0.7276\n",
      "Epoch 201/300\n",
      "1972/1972 [==============================] - 1s 720us/step - loss: 0.5388 - accuracy: 0.7266\n",
      "Epoch 202/300\n",
      "1972/1972 [==============================] - 1s 658us/step - loss: 0.5390 - accuracy: 0.7268\n",
      "Epoch 203/300\n",
      "1972/1972 [==============================] - 1s 713us/step - loss: 0.5388 - accuracy: 0.7276\n",
      "Epoch 204/300\n",
      "1972/1972 [==============================] - 1s 687us/step - loss: 0.5389 - accuracy: 0.7279\n",
      "Epoch 205/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5385 - accuracy: 0.7276\n",
      "Epoch 206/300\n",
      "1972/1972 [==============================] - 1s 664us/step - loss: 0.5386 - accuracy: 0.7280\n",
      "Epoch 207/300\n",
      "1972/1972 [==============================] - 1s 658us/step - loss: 0.5389 - accuracy: 0.7275\n",
      "Epoch 208/300\n",
      "1972/1972 [==============================] - 1s 649us/step - loss: 0.5389 - accuracy: 0.7269\n",
      "Epoch 209/300\n",
      "1972/1972 [==============================] - 1s 697us/step - loss: 0.5389 - accuracy: 0.7281\n",
      "Epoch 210/300\n",
      "1972/1972 [==============================] - 2s 762us/step - loss: 0.5387 - accuracy: 0.7285\n",
      "Epoch 211/300\n",
      "1972/1972 [==============================] - 2s 765us/step - loss: 0.5390 - accuracy: 0.7276\n",
      "Epoch 212/300\n",
      "1972/1972 [==============================] - 1s 751us/step - loss: 0.5389 - accuracy: 0.7269\n",
      "Epoch 213/300\n",
      "1972/1972 [==============================] - 1s 690us/step - loss: 0.5390 - accuracy: 0.7285\n",
      "Epoch 214/300\n",
      "1972/1972 [==============================] - 1s 688us/step - loss: 0.5388 - accuracy: 0.7275\n",
      "Epoch 215/300\n",
      "1972/1972 [==============================] - 1s 674us/step - loss: 0.5387 - accuracy: 0.7288\n",
      "Epoch 216/300\n",
      "1972/1972 [==============================] - 1s 726us/step - loss: 0.5388 - accuracy: 0.7272\n",
      "Epoch 217/300\n",
      "1972/1972 [==============================] - 1s 711us/step - loss: 0.5387 - accuracy: 0.7280\n",
      "Epoch 218/300\n",
      "1972/1972 [==============================] - 1s 651us/step - loss: 0.5386 - accuracy: 0.7284\n",
      "Epoch 219/300\n",
      "1972/1972 [==============================] - 1s 732us/step - loss: 0.5385 - accuracy: 0.7274\n",
      "Epoch 220/300\n",
      "1972/1972 [==============================] - 2s 775us/step - loss: 0.5388 - accuracy: 0.7284\n",
      "Epoch 221/300\n",
      "1972/1972 [==============================] - 1s 749us/step - loss: 0.5387 - accuracy: 0.7276\n",
      "Epoch 222/300\n",
      "1972/1972 [==============================] - 1s 746us/step - loss: 0.5389 - accuracy: 0.7274\n",
      "Epoch 223/300\n",
      "1972/1972 [==============================] - 2s 782us/step - loss: 0.5386 - accuracy: 0.7277\n",
      "Epoch 224/300\n",
      "1972/1972 [==============================] - 1s 717us/step - loss: 0.5388 - accuracy: 0.7276\n",
      "Epoch 225/300\n",
      "1972/1972 [==============================] - 1s 744us/step - loss: 0.5389 - accuracy: 0.7272\n",
      "Epoch 226/300\n",
      "1972/1972 [==============================] - 1s 712us/step - loss: 0.5388 - accuracy: 0.7272\n",
      "Epoch 227/300\n",
      "1972/1972 [==============================] - 1s 674us/step - loss: 0.5386 - accuracy: 0.7266\n",
      "Epoch 228/300\n",
      "1972/1972 [==============================] - 1s 623us/step - loss: 0.5388 - accuracy: 0.7270\n",
      "Epoch 229/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5388 - accuracy: 0.7271\n",
      "Epoch 230/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5386 - accuracy: 0.7270\n",
      "Epoch 231/300\n",
      "1972/1972 [==============================] - 1s 675us/step - loss: 0.5387 - accuracy: 0.7280\n",
      "Epoch 232/300\n",
      "1972/1972 [==============================] - 1s 684us/step - loss: 0.5387 - accuracy: 0.7281\n",
      "Epoch 233/300\n",
      "1972/1972 [==============================] - 1s 672us/step - loss: 0.5386 - accuracy: 0.7287\n",
      "Epoch 234/300\n",
      "1972/1972 [==============================] - 1s 682us/step - loss: 0.5387 - accuracy: 0.7286\n",
      "Epoch 235/300\n",
      "1972/1972 [==============================] - 1s 671us/step - loss: 0.5388 - accuracy: 0.7278\n",
      "Epoch 236/300\n",
      "1972/1972 [==============================] - 1s 684us/step - loss: 0.5391 - accuracy: 0.7271\n",
      "Epoch 237/300\n",
      "1972/1972 [==============================] - 1s 701us/step - loss: 0.5382 - accuracy: 0.7279\n",
      "Epoch 238/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5386 - accuracy: 0.7273\n",
      "Epoch 239/300\n",
      "1972/1972 [==============================] - 1s 642us/step - loss: 0.5387 - accuracy: 0.7269\n",
      "Epoch 240/300\n",
      "1972/1972 [==============================] - 1s 680us/step - loss: 0.5387 - accuracy: 0.7272\n",
      "Epoch 241/300\n",
      "1972/1972 [==============================] - 1s 654us/step - loss: 0.5389 - accuracy: 0.7273\n",
      "Epoch 242/300\n",
      "1972/1972 [==============================] - 1s 712us/step - loss: 0.5387 - accuracy: 0.7284\n",
      "Epoch 243/300\n",
      "1972/1972 [==============================] - 2s 890us/step - loss: 0.5390 - accuracy: 0.7273\n",
      "Epoch 244/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5387 - accuracy: 0.7274\n",
      "Epoch 245/300\n",
      "1972/1972 [==============================] - 1s 661us/step - loss: 0.5384 - accuracy: 0.7277\n",
      "Epoch 246/300\n",
      "1972/1972 [==============================] - 1s 692us/step - loss: 0.5388 - accuracy: 0.7285\n",
      "Epoch 247/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5385 - accuracy: 0.7278\n",
      "Epoch 248/300\n",
      "1972/1972 [==============================] - 1s 679us/step - loss: 0.5386 - accuracy: 0.7281\n",
      "Epoch 249/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5387 - accuracy: 0.7275\n",
      "Epoch 250/300\n",
      "1972/1972 [==============================] - 1s 716us/step - loss: 0.5387 - accuracy: 0.7278\n",
      "Epoch 251/300\n",
      "1972/1972 [==============================] - 1s 688us/step - loss: 0.5388 - accuracy: 0.7275\n",
      "Epoch 252/300\n",
      "1972/1972 [==============================] - 1s 655us/step - loss: 0.5385 - accuracy: 0.7269\n",
      "Epoch 253/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5388 - accuracy: 0.7279\n",
      "Epoch 254/300\n",
      "1972/1972 [==============================] - 1s 641us/step - loss: 0.5389 - accuracy: 0.7263\n",
      "Epoch 255/300\n",
      "1972/1972 [==============================] - 1s 669us/step - loss: 0.5390 - accuracy: 0.7273\n",
      "Epoch 256/300\n",
      "1972/1972 [==============================] - 1s 659us/step - loss: 0.5384 - accuracy: 0.7292\n",
      "Epoch 257/300\n",
      "1972/1972 [==============================] - 1s 639us/step - loss: 0.5388 - accuracy: 0.7280\n",
      "Epoch 258/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5387 - accuracy: 0.7280\n",
      "Epoch 259/300\n",
      "1972/1972 [==============================] - 1s 649us/step - loss: 0.5387 - accuracy: 0.7272\n",
      "Epoch 260/300\n",
      "1972/1972 [==============================] - 1s 651us/step - loss: 0.5388 - accuracy: 0.7273\n",
      "Epoch 261/300\n",
      "1972/1972 [==============================] - 2s 771us/step - loss: 0.5388 - accuracy: 0.7283\n",
      "Epoch 262/300\n",
      "1972/1972 [==============================] - 2s 762us/step - loss: 0.5385 - accuracy: 0.7282\n",
      "Epoch 263/300\n",
      "1972/1972 [==============================] - 1s 712us/step - loss: 0.5385 - accuracy: 0.7287\n",
      "Epoch 264/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5391 - accuracy: 0.7274\n",
      "Epoch 265/300\n",
      "1972/1972 [==============================] - 1s 685us/step - loss: 0.5386 - accuracy: 0.7273\n",
      "Epoch 266/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5387 - accuracy: 0.7276\n",
      "Epoch 267/300\n",
      "1972/1972 [==============================] - 1s 725us/step - loss: 0.5387 - accuracy: 0.7288\n",
      "Epoch 268/300\n",
      "1972/1972 [==============================] - 1s 652us/step - loss: 0.5386 - accuracy: 0.7269\n",
      "Epoch 269/300\n",
      "1972/1972 [==============================] - 1s 680us/step - loss: 0.5386 - accuracy: 0.7267\n",
      "Epoch 270/300\n",
      "1972/1972 [==============================] - 1s 642us/step - loss: 0.5387 - accuracy: 0.7278\n",
      "Epoch 271/300\n",
      "1972/1972 [==============================] - 1s 679us/step - loss: 0.5388 - accuracy: 0.7277\n",
      "Epoch 272/300\n",
      "1972/1972 [==============================] - 1s 673us/step - loss: 0.5388 - accuracy: 0.7274\n",
      "Epoch 273/300\n",
      "1972/1972 [==============================] - 1s 678us/step - loss: 0.5385 - accuracy: 0.7283\n",
      "Epoch 274/300\n",
      "1972/1972 [==============================] - 1s 634us/step - loss: 0.5389 - accuracy: 0.7276\n",
      "Epoch 275/300\n",
      "1972/1972 [==============================] - 1s 679us/step - loss: 0.5385 - accuracy: 0.7279\n",
      "Epoch 276/300\n",
      "1972/1972 [==============================] - 1s 631us/step - loss: 0.5389 - accuracy: 0.7278\n",
      "Epoch 277/300\n",
      "1972/1972 [==============================] - 1s 674us/step - loss: 0.5385 - accuracy: 0.7280\n",
      "Epoch 278/300\n",
      "1972/1972 [==============================] - 1s 647us/step - loss: 0.5387 - accuracy: 0.7284\n",
      "Epoch 279/300\n",
      "1972/1972 [==============================] - 1s 693us/step - loss: 0.5387 - accuracy: 0.7275\n",
      "Epoch 280/300\n",
      "1972/1972 [==============================] - 1s 759us/step - loss: 0.5385 - accuracy: 0.7276\n",
      "Epoch 281/300\n",
      "1972/1972 [==============================] - 1s 731us/step - loss: 0.5387 - accuracy: 0.7285\n",
      "Epoch 282/300\n",
      "1972/1972 [==============================] - 1s 722us/step - loss: 0.5388 - accuracy: 0.7279\n",
      "Epoch 283/300\n",
      "1972/1972 [==============================] - 1s 670us/step - loss: 0.5386 - accuracy: 0.7277\n",
      "Epoch 284/300\n",
      "1972/1972 [==============================] - 1s 681us/step - loss: 0.5387 - accuracy: 0.7282\n",
      "Epoch 285/300\n",
      "1972/1972 [==============================] - 1s 687us/step - loss: 0.5388 - accuracy: 0.7276\n",
      "Epoch 286/300\n",
      "1972/1972 [==============================] - 1s 653us/step - loss: 0.5386 - accuracy: 0.7276\n",
      "Epoch 287/300\n",
      "1972/1972 [==============================] - 1s 677us/step - loss: 0.5387 - accuracy: 0.7269\n",
      "Epoch 288/300\n",
      "1972/1972 [==============================] - 1s 658us/step - loss: 0.5388 - accuracy: 0.7282\n",
      "Epoch 289/300\n",
      "1972/1972 [==============================] - 1s 665us/step - loss: 0.5386 - accuracy: 0.7270\n",
      "Epoch 290/300\n",
      "1972/1972 [==============================] - 1s 680us/step - loss: 0.5387 - accuracy: 0.7268\n",
      "Epoch 291/300\n",
      "1972/1972 [==============================] - 2s 798us/step - loss: 0.5388 - accuracy: 0.7280\n",
      "Epoch 292/300\n",
      "1972/1972 [==============================] - 1s 745us/step - loss: 0.5386 - accuracy: 0.7282\n",
      "Epoch 293/300\n",
      "1972/1972 [==============================] - 2s 767us/step - loss: 0.5388 - accuracy: 0.7274\n",
      "Epoch 294/300\n",
      "1972/1972 [==============================] - 1s 748us/step - loss: 0.5385 - accuracy: 0.7280\n",
      "Epoch 295/300\n",
      "1972/1972 [==============================] - 2s 825us/step - loss: 0.5385 - accuracy: 0.7279\n",
      "Epoch 296/300\n",
      "1972/1972 [==============================] - 2s 786us/step - loss: 0.5386 - accuracy: 0.7275\n",
      "Epoch 297/300\n",
      "1972/1972 [==============================] - 2s 796us/step - loss: 0.5387 - accuracy: 0.7272\n",
      "Epoch 298/300\n",
      "1972/1972 [==============================] - 2s 806us/step - loss: 0.5386 - accuracy: 0.7283\n",
      "Epoch 299/300\n",
      "1972/1972 [==============================] - 2s 832us/step - loss: 0.5385 - accuracy: 0.7279\n",
      "Epoch 300/300\n",
      "1972/1972 [==============================] - 2s 828us/step - loss: 0.5387 - accuracy: 0.7278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219f3ee44c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=9))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# Train the model several times to improve accuracy\n",
    "model.fit(pred_train,res_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 0s 544us/step\n",
      "The accuracy score achieved using Neural Network is: 72.6 %\n"
     ]
    }
   ],
   "source": [
    "res_pred_nn = model.predict(pred_test)\n",
    "rounded = [round(x[0]) for x in res_pred_nn]\n",
    "\n",
    "res_pred_nn = rounded\n",
    "score_nn = round(accuracy_score(res_pred_nn,res_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Random Forest is: 69.27 %\n",
      "The accuracy score achieved using Decision Tree is: 65.07 %\n",
      "The accuracy score achieved using K-Nearest Neighbors is: 69.88 %\n",
      "The accuracy score achieved using Neural Network is: 72.6 %\n"
     ]
    }
   ],
   "source": [
    "scores = [score_rf,score_dt,score_knn,score_nn]\n",
    "models = [\"Random Forest\",\"Decision Tree\",\"K-Nearest Neighbors\",\"Neural Network\"]    \n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"The accuracy score achieved using \"+models[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "\n",
    "barPlot = sns.barplot(x=models,y=scores)\n",
    "for i in barPlot.containers:\n",
    "    barPlot.bar_label(i,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
